\documentclass{article}


%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Scalable estimation of hierarchical models}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{placeins} %% for \FloatBarrier
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{parskip}
\usepackage{setspace}
\linespread{1.2}

%%make knitr environment line spacing separate from LaTeX
\renewenvironment{knitrout}{\begin{singlespace}}{\end{singlespace}}



\DeclareMathOperator\logit{logit}
\DeclareMathOperator\Chol{Chol }
\DeclareMathOperator\cov{cov}

\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\func}[1]{\texttt{#1}}
\newcommand{\class}[1]{\texttt{#1}}
\newcommand{\funcarg}[1]{\texttt{#1}}
\newcommand{\filename}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\variable}[1]{\texttt{#1}}
\newcommand{\method}[1]{\textbf{#1}}

 \newcommand{\Prior}{\pi(\theta)}
 \newcommand{\Post}{\pi(\theta|y)}
 \newcommand{\Gtheta}{g(\theta)}
 \newcommand{\Phitheta}{\Phi(\theta|y)}
 \newcommand{\Ly}{\mathcal{L}(y)}
 \newcommand{\Dy}{\mathcal{D}(\theta,y)}


\usepackage[style=authoryear,%
			backend=biber,%
			maxbibnames=99,%
                        bibencoding=utf8,%
                        maxcitenames=1,
                        citetracker=true,
                        dashed=false,
                        maxalphanames=1,%
                        backref=false,%
			doi=false,%
			isbn=false,%
                        mergedate=basic,%
                        dateabbrev=true,%
                        natbib=true,%
                        uniquename=false,%
                        uniquelist=false,%
                        useprefix=true,%
                        firstinits=false
			]{biblatex}

 \addbibresource{/Users/braunm/OneDriveBusiness/References/Papers/braun_refs.bib}

 \setlength{\bibitemsep}{1em}
\AtEveryCitekey{\ifciteseen{}{\defcounter{maxnames}{2}}}
\DeclareFieldFormat[article,incollection,unpublished]{title}{#1} %No quotes for article titles
\DeclareFieldFormat[thesis]{title}{\mkbibemph{#1}} % Theses like book
                                % titles
\DeclareFieldFormat{pages}{#1} %% no pp prefix before page numbers
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{ % Don't print In: for journal articles
  \printtext{\bibstring{in}\intitlepunct}} %% but use elsewhere
}
\renewbibmacro*{volume+number+eid}{%
  \printfield{volume}%
  \printfield{number}%
  \setunit{\addcomma\addspace}%
  \printfield{eid}}

\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{date}{#1}
\AtEveryBibitem{\clearfield{day}}

\renewbibmacro*{issue+date}{% print month only
  \printtext{%
    \printfield{issue}\addspace%
    \newunit%
%\printtext{\printfield{month}}%
}
  \newunit}

\renewbibmacro*{publisher+location+date}{% no print year
  \printlist{location}%
  \iflistundef{publisher}
    {\setunit*{\addcomma\space}}
    {\setunit*{\addcolon\space}}%
  \printlist{publisher}%
  \setunit*{\addcomma\space}%
%%\printdate
  \newunit}

\renewcommand*{\nameyeardelim}{~} %no comma in cite
\renewcommand{\bibitemsep}{1ex}
\def\bibfont{\small}


\begin{document}

<<setup1, echo=FALSE, cache=FALSE>>=
knitr::opts_chunk[["set"]](collapse = FALSE, eval=TRUE, echo=TRUE, comment = "#",
                           message=FALSE, tidy=FALSE) #
knitr::read_chunk("binary_chunks.R")
@ 


\citet{BraunDamien2015}, henceforth known as BD, introduce a method of
sampling from posterior distributions. The main advantage of BD over MCMC is
that samples can be collected in parallel.  Furthermore, the algorithm
is scalable for hierarchical models with conditionally independent
heterogeneous units.  These features make BD an attractive estimation method
for Bayesian hierarchical models of large datasets.  We assume that the reader
has read that paper, and has a general familiarity with the method.  For convenience, Algorithm 1 in \citet{BraunDamien2015} is
reprinted here as Algorithm \ref{alg:GDS}.  

A common reaction to the BD algorithm, and especially to the need to find
the posterior mode, is ``easier said than done.''  We suspect that this reaction comes
from people who use existing \proglang{R} functions and package that
are not particularly scalable.  Examples include using the \func{optim}
function in base \proglang{R} to find the posterior model, and the
\func{rmvnorm} function in the \pkg{mvtnorm} package for sampling from
a multivariate normal (MVN) random variable.  These are packages with which 
most \proglang{R} users are familiar, so it is understandable that the
barrier to adoption of algorithms that fail when using them would be high.

%% Informally, the steps of the algorithm can be grouped 
%% into three ``phases:''

%% \begin{enumerate}
%% \item Find the posterior mode;
%% \item Estimate the marginal density of threshold variables; and
%% \item Collect posterior draws through a modified rejection sampling process.
%% \end{enumerate}

\begin{algorithm}
\caption{Algorithm to collect $R$ samples from $\Post$}
\label{alg:GDS}
\begin{algorithmic}[1]
\STATE{$R\leftarrow$ number of required samples from $\Post$}
\STATE{$M\leftarrow$ number
  of proposal draws for estimating $\widehat{q}_v(v)$.}
\STATE{$\theta^*\leftarrow$ mode of $\Dy$}
\STATE{$c_1\leftarrow\mathcal{D}(\theta^*,y)$}
\STATE{{\tt FLAG}$\leftarrow$ {\tt TRUE}}
\WHILE{{\tt FLAG}}
\STATE{Choose new proposal distribution $\Gtheta$}
\STATE{{\tt FLAG}$\leftarrow${\tt FALSE}}
\STATE{$c_2\leftarrow g(\theta^*)$.}
\FOR{$m:=1$ \TO $M$}
\STATE{Sample $\theta_m \sim \Gtheta$.}
\STATE{$\log\Phi(\theta_m|y)\leftarrow
  \log\mathcal{D}(\theta_m,y)-\log g(\theta_m)-\log c_1 + \log c_2$.}
\STATE{$v_m=-\log\Phi(\theta_m|y)$}
\IF{$\log\Phi(\theta_m|y)>0$}
\STATE {{\tt FLAG}$\leftarrow$ {\tt TRUE}}
\STATE{{\bf break}}
\ENDIF
\ENDFOR
\ENDWHILE
\STATE{Reorder elements of $v$, so
  $0<v_1<v_2<\mathellipsis <v_M<\infty$. Define $v_{M+1}:=\infty$}
\FOR{$i:=1$ \TO $M$}
 \STATE{$\widehat{q}_v(v_i)\leftarrow\sum_{j=1}^M\mathbb{1}\left[v_j<v_i\right]$.}
\STATE{ $\varpi_i\leftarrow \widehat{q}_v(v_i)\left[\exp(-v_i)-\exp(-v_{i+1})\right]$.}
\ENDFOR
\FOR{$r=1$ \TO $R$}
\STATE{Sample $j\sim$ Multinomial$(\varpi_1\mathellipsis\varpi_M)$.}
\STATE{Sample $\eta\sim$ Uniform(0,1).}
\STATE{$v^*\leftarrow v_j-\log\left[1-\eta\left( 1-\exp\left( v_j-v_{j+1}\right)\right)\right]$.}
\STATE{$p\leftarrow 0$}
\STATE{$n_r\leftarrow 0$.  }\COMMENT{Counter for number of proposals}
\WHILE{$p > v^*$}
\STATE{Sample $\theta_r\sim\Gtheta$.}
\STATE{$p\leftarrow -\log\Phi\left(\theta_r|y\right)$.}
\STATE{$n_r\leftarrow n_r+1$.}
\ENDWHILE
\ENDFOR
\RETURN{$\theta_1\mathellipsis \theta_R$ (plus $n_1\mathellipsis n_R$ and $v_1\mathellipsis v_M$
  if computing a marginal likelihood).}
\end{algorithmic}
\end{algorithm}


In this note, we explain how one can implement the BD algorithm in a
scalable way, using packages that were written with that algorithm
in mind.  These packages, listed in Table \ref{tab:packages}, are
required to run the code in this vignette.  The \pkg{Matrix} and \pkg{sparseHessianFD} define
classes for working with sparse matrices, and the 
\pkg{sparseMVN}, and \pkg{trustOptim} packages respectively provide sampling and
optimization routines that are designed to work with sparse matrices.
The \pkg{bayesGDS} package implements the posterior sampling phase of
the BD algorithm.  Table \ref{tab:packages} also refers to the lines
in Algorithm \ref{alg:GDS} that are relevant to each package.


\begin{table}[htb]
  \centering
  \begin{tabular}{p{1.5in} p{3in} p{1in}}
    Package&Specific use for the BD algorithm&Relevant lines in
                                               Algorithm\\
\hline
    \pkg{Matrix}&Defines classes to store sparse matrices in a compressed
            format, and functions to work with, and to decompose,
            sparse matrices efficiently.&3, 11, 32\\
    \hline
    \pkg{sparseHessianFD}&For numerical estimation of sparse Hessians when
                     the gradient and sparsity pattern are both
                           known&Setup, 3, 11, 32\\
    \hline
    \pkg{sparseMVN}&Efficient functions to sample from, and to compute the
               log density of, a multivariate normal (MVN) random
               variable for which either the covariance or precision
               matrix is sparse. &11, 12, 32, 33\\
    \hline
    \pkg{trustOptim}&a package for nonlinear optimization that is efficient
                when the objective function has a sparse Hessian.&3\\
    \hline
    \pkg{bayesGDS} (this package)&Rejection sampling from target posterior, and
                    computing log marginal likelihood&20-37\\
    \hline
  \end{tabular}
  \caption{\proglang{R} packages that will be used in this note.}
  \label{tab:packages}
\end{table}







\section{Some background}

The goal is to sample a
parameter vector $\theta$ from a posterior density $\pi(\theta|y)$,
where $\pi(\theta)$ is the prior on $\theta$, $f(y|\theta)$ is the data
likelihood conditional on $\theta$, and $\mathcal{L}(y)$ is the marginal
likelihood of the data.  Therefore,
\begin{align}
\pi(\theta|y)=\frac{f(y|\theta)\pi(\theta)}{\mathcal{L}(y)}=\frac{\mathcal{D}(\theta,y)}{\mathcal{L}(y)}
\end{align}
where $\mathcal{D}(\theta,y)$ is the joint
density of the data and the parameters (of the unnormalized posterior
density).

Under the conditional
independence assumption, the likelihood can be factored as

\begin{align}
f(y|\theta)=\prod_{i=1}^Nf_i\left(y_i|\beta_i,\alpha\right)
\end{align}

where $i$ indexes households. Each $y_i$ is a vector of observed data, each $\beta_i$ is a vector of
heterogeneous parameters, and $\alpha$ is a vector of homogeneous population-level
parameters.  The $\beta_i$ are distributed across the population of
households according to a mixing distribution $\pi(\beta_i|\alpha)$,
which also serves as the prior on each $\beta_i$.  The elements of $\alpha$
may influence either the household-level data likelihoods, or the
mixing distribution (or both).  In this example, $\theta$ includes all 
$\beta_1\mathellipsis\beta_N$ and all elements of $\alpha$.  The
prior itself can be factored as
\begin{align}
\pi(\theta)=\prod_{i=1}^N\pi_i(\beta_i|\alpha)\times\pi(\alpha).
\end{align}

Thus, the log posterior density is written as
\begin{align}
\log \pi(\beta,\alpha|y)&=\sum_{i=1}^N\left[\log f(y_i|\beta_i)+\log\pi(\beta_i|\alpha)\right]+\log\pi(\alpha)-\log\mathcal{L}(y)
\end{align}

\subsection{Sparse Hessians}

An implication of the conditional independence
assumption is that the cross-partial derivatives
$\dfrac{\partial^2\log\pi}{\beta_i\beta_j}$ are zero for all $i\neq
j$. As the number of households in the dataset increases, the number
of elements in the Hessian matrix increases quadratically, but the
number of \emph{non-zero} elements increases only linearly.  Thus, the
Hessian becomes sparser as the data set gets larger.

<<setup2, echo=FALSE>>=
@ 

Suppose we have a hierarchical model with $N$ heterogeneous units,
each with a parameter vector of length $k$.  Also, assume that there
are $p$ population-level parameters or hyperparameters.

The \emph{sparsity pattern} of the Hessian depends on how the variables are
ordered within the vector. One such ordering is to group all of the
coefficients for each unit together.
\begin{align}
\beta_{11},...,\beta_{1k},\beta_{21},...,\beta_{2k},...~,~...~,~\beta_{N1}~,~...~,~\beta_{Nk},\mu_1,...,\mu_p
\end{align}

In this case, the Hessian has a "block-arrow" structure.  For example,
if $N=\Sexpr{NN}$, $k=\Sexpr{kk}$, and $p=\Sexpr{pp}$, then there are
\Sexpr{nv1} total variables, and the Hessian will have the sparsity
pattern in Figure \ref{fig:pattern1}.

Another option would be to group the coefficients by covariate.
\begin{align}
\beta_{11},...,\beta_{1N},\beta_{21},...,\beta_{2N},...,...,\beta_{k1},...,\beta_{kN},\mu_1,...,\mu_p
\end{align}

Now the Hessian has an "off-diagonal" sparsity pattern, as in Figure \ref{fig:pattern2}.

\begin{figure}
  \begin{subfigure}[t]{.5\linewidth}
<<pattern1, echo=FALSE>>==
@ 
\caption{A ``block-arrow'' sparsity pattern}\label{fig:pattern1}
\end{subfigure}
\begin{subfigure}[t]{.5\linewidth}
<<pattern2, echo=FALSE>>=
@
\caption{An ``off-diagonal'' sparsity pattern.}\label{fig:pattern2}
\end{subfigure}
\caption{Examples of sparsity patterns for a hierarchical model.  The
  pattern depends on the ordering of the coefficients. The
  \class{lgCMatrix} class is defined in the \pkg{Matrix} package.}
\end{figure}



In both cases, the number of non-zeros is the same.  There are
\Sexpr{nels1} elements in this symmetric matrix, but only  \Sexpr{nnz1} are
non-zero, and only \Sexpr{nnz1LT} values are unique.  Although in this
example the reduction in
RAM from using a sparse matrix structure for the Hessian may be
modest, consider what would happen if $N=\Sexpr{Q}$ instead.  In that case,
there are $\Sexpr{format(nv2, scientific=FALSE, big.mark=",")}$
variables in the problem, and more than $\Sexpr{floor(nels2/10^6)}$ million
elements in the Hessian.  However, only $\Sexpr{format(nnz2, scientific=FALSE, big.mark=",")}$ of those elements are
non-zero.  If we work with only the lower triangle of the Hessian we only need to work with
only $\Sexpr{format(nnz2LT, scientific=FALSE, big.mark=",")}$ values.


\subsection{Computing derivatives}

Functions that return the gradient and Hessian of the unnormalized log
posterior density can be
useful both for finding the posterior mode, and for sampling from, and
computing the density of, a multivariate normal (MVN) distribution.  In our opinion, there are two "good" ways to compute a gradient.  The
first is to derive it analytically, and write a function to compute
it.  This approach is straightforward, but it can be tedious and
error-prone for complicated models.

The second is to use automatic,
or algorithmic, differentiation (AD).  In short, AD is an automated
way of applying the chain rule through the same sequence of operations
that computes the LPD.  There are a number of different approaches to
implementing AD, such as using a software library of specialized
numerical types and operations.  While AD libraries are available for
\proglang{Matlab}, \proglang{Python}, \proglang{C++} and \proglang{Fortran}, there are none for R that are
well-suited for a general class of Bayesian hierarchical models.  For
\proglang{R} users, we believe that coding the LPD in \proglang{C++} using the \pkg{ADOL-C} or
\pkg{CppAD} libraries, and interfacing with \proglang{R} using \pkg{Rcpp}, is the best option
at the moment.  How to do this will be the subject of a future
vignette.  What matters is that functions that return the gradient and
Hessian of the log posterior density are available, and that they are sufficiently
accurate. 

The advantages of these two methods is that the gradient is exact.
This feature is in contrast to numerical approximation via finite
differencing (FD), which we consider a "bad" way to provide a gradient for
the BD algorithm.  FD differencing involves computing
$\dfrac{\partial f}{\partial x_j}\approx\dfrac{f(x_j+h)-f(x_j)}{h}$,
or some variation thereof, for each of the $j=1...J$ variables,
using an arbitrarily small $h$ as a ``perturbation factor.''  As $h\rightarrow 0$, this estimated
difference approaches the gradient.  There are two problems with
this approach.  First, the estimate is not exact.  If $h$ is too
large, the result is not close enough to the true gradient.  If $h$ is
too small, the result may be subject to numerical precision issues. Second, this computation needs to be done for each
element of the variable vector.  Thus, the time it takes to compute
the gradient grows with the number of units or variables in the
model. In contrast, the time to compute a gradient using AD methods is
a small fixed constant times the time to compute the function itself \citep{GriewankWalther2008}.
The time to compute a analytically-derived gradient depends on how the gradient function is implemented.

Deriving a Hessian analytically can be even more tedious and
error-prone than deriving a gradient, so AD is the preferred method.
Both \pkg{CppAD} and \pkg{ADOL-C} can return a sparse Hessian in a compressed
format.

If using AD to compute the Hessian is not an option, one can use
finite differencing if the Hessian is sparse, \emph{and} the
sparsity pattern is known in advance, \emph{and} the gradient is
exact (either derived analytically or computed using AD).  The
\pkg{sparseHessianFD} package defines an \proglang{R} class for doing this. An object
of class \class{sparseHessianFD} is constructed by providing
functions that return the value of the log density and its gradient; any additional
arguments that are passed to these functions; and the row
and column indices of the non-zero elements of the lower triangle of
the Hessian.  Once the \class{sparseHessianFD} object is constructed,
one can call the log density, the gradient, and the Hessian directly
from the object.  The Hessian is returned as a \class{dgCMatrix}
object, which is a sparse, compressed representation.  More details are in
the \pkg{sparseHessianFD} documentation.

The \class{sparseHessianFD} class is especially useful for
hierarchical models because, as we discussed in Section XX, the
sparsity pattern of a hierarchical model is often easily predictable.
Even if a function that returns the values of the Hessian is
available, it still may be faster to use \class{sparseHessianFD} for
repeated estimation.  Given the typical sparsity pattern of a hierarchical model, the time to estimate
a Hessian using \pkg{sparseHessianFD} does not grow with the number of
heterogeneous units, making it a particularly scalable way of
estimating sparse Hessians for large datasets.

The trade-off from using the \pkg{sparseHessianFD} package is that the
Hessian is still a numerical approximation.  We cannot guarantee that
this approximation is "good enough" for all cases.  However, the
performance of an optimization algorithm is likely more sensitive to
numerical imprecision in the gradient than in the Hessian. Thus, we
are comfortable working with finite-differenced Hessians, even though
we will not use finite-differenced gradients.  This approach will
almost certainly fail if the gradient itself is estimated using FD, because
the estimate of the Hessian would be a finite difference of finite
differences, with too much numerical imprecision to be of much
value.

In summary, there are a few points to keep in mind with regard to
derivatives of the log posterior density:

\begin{enumerate}
\item Use gradients and Hessians for numerical optimization wherever
  possible (see Section \ref{sec:optimization});
\item The gradient needs to be exact, either through deriving and
  coding it directly, or from computation via automatic
  differentiation, but not through finite differencing;
\item if the Hessian is sparse, the Hessian function should return a
  compressed sparse matrix; and
\item it may be acceptable to use finite-differenced approximations to
  the Hessian if the Hessian is sparse, and the estimation algorithm
  takes that sparsity into account.
\end{enumerate}


\subsection{Nonlinear optimization}\label{sec:optimization}

Many researchers' initial reaction to the BD algorithm is that
the task of finding the posterior mode of the LPD is easier said than
done. This view is certainly true if it is informed by previous
experience with the standard optimization algorithms in \proglang{R} (e.g., the
\func{optim} function).  There are two characteristics of these algorithms
that can cause problems:

1.  The stopping rule of \func{optim} is based on whether the optimizer is
    making "sufficient" progress, in either the value of the
    objective function, or in the values of the optimization
    variables.  Neither of these are appropriate conditions for having
    found a local optimum in unconstrained problems.  Instead, the
    algorithm should not stop until the derivative is zero, at least
    up to machine precision. 

2.  The default optimization method in \func{optim} is a derivative-free
    search algorithm known as ``Nelder-Mead."  When the search for
    variables that improve the objective function is conducted in a
    large number of directions, the time to converge can be quite
    high.  The \func{optim} function provides some derivative-based
    algorithms that use successive estimates of the gradient to
    approximate the curvature of the objecvtive function, such as
    quasi-Newton (\method{BFGS}), conjugate gradient (\method{CG}), and limited-memory
    \method{BFGS}. \method{BFGS} gives the most "complete" estimate of the Hessian, but
    needs to store that approximation in a matrix that grows
    quadratically with the number of variables.  \method{CG} and \method{L-BFGS} are more
    suited for large-scale problems, but depend on the accuracy of the
    Hessian approximation for rapid convergence to the local optimum.

To facilitate fast convergence to the posterior mode, we should prefer
an algorithm that uses exact calculations of the gradient and Hessian,
remains scalable for large problems, stops only when the norm of the
gradient is numerically zero, and is stable when passing through
regions in which the surface of the objective function is flat.  The \func{trust.optim} function
in the \pkg{trustOptim} package meets those criteria.  To use
\func{trust.optim}, the user must provide R functions that return the value
and gradient of the function.  To use an algorithm that is scalable for problems
with sparse Hessians, the user must also provide a function that
returns the Hessian as a \class{dgCMatrix} object (a compressed sparse
matrix format defined in the \pkg{Matrix} package).  Details about the
underlying algorithm are available in \citet{R_trustOptim}.


The \pkg{trustOptim} package provides a function for unconstrained
nonlinear optimization that has a few advantages over other optimizers
that are available for R.

1.  It uses a "trust region" algorithm, that may be more stable for
    certain types of objective functions, especially those that are
	poorly conditioned, or have regions that are nearly flat.   	
	
2.  The user can accelerate the optimization routine by providing a function that returns the Hessian as a sparse object.

3.  The stopping rule is based on the norm of the gradient, and not
    whether the optimization is making "sufficient progress."  This
    means that the optimizer is less like to halt at a value at which
    the gradient is not really flat.

The documentation for the \pkg{trustOptim} package provides much more
detail about the algorithm, and the arguments to the \func{trust.optim}
function.  For this example, we use the member functions of the FD
object to return the log posterior density, gradient and Hessian.  We
do not need to provide \funcarg{data} and \funcarg{priors}, since those are already
stored in FD.




\subsection{Large-scale proposal densities}

Another potential source of poor scalability is in sampling from, and
computing the log density of, a multivariate normal (MVN)
distribution. The \func{rmvnorm} and \func{dmvnorm} functions from the
\pkg{mvtnorm} package are inefficient
in the context of the BD algorithm for three reasons.  First, they
require the covariance matrix as one of the arguments, meaning that
the negative Hessian must be inverted explicitly.  Second, they do not
exploit the sparsity of the Hessian for computational gain.  Third,
the \func{rmvnorm} function performs a matrix factorization every time it
is called, even if the covariance matrix has not changed.

The \pkg{sparseMVN} package solves these problems.  The \func{rmvn.sparse} and
\func{dmvn.sparse} functions take, as one of the arguments, the Cholesky
decomposition of either a sparse covariance or sparse precision
matrix.  Thus, the user has a choice of provide either the covariance
or precision matrix, depending on which is more convenient.  While the
user does have to generate the sparse Cholesky decomposition first,
the Cholesky object is in a sparse, compressed format.  Since the size
of the sparse Hessian grows only linearly with the size of the
dataset, the \pkg{sparseMVN} package is a scalable alternative for working
with an MVN.  More details are available in the \pkg{sparseMVN}
documentation and vignette, as well as in the example below. 

\section{Example:  hierarchical binary choice}\label{sec:example}

Before going into the details of how to use the package, let's
consider the following example of a log posterior density function
with a sparse Hessian.
 Suppose we have a dataset of $N$ households, each with $T$
 opportunities to purchase a particular product.  Let $y_i$ be the
 number of times household $i$ purchases the product, out of the $T$
 purchase opportunities.  Furthermore, let $p_i$ be the probability of
 purchase; $p_i$ is the same for all $T$ opportunities, so we can treat $y_i$ as a binomial random variable.  The purchase probability
 $p_i$ is heterogeneous, and depends on both $k$ continuous covariates
 $x_i$, and a heterogeneous coefficient vector $\beta_i$, such that
\begin{align}
  p_i=\frac{\exp(x_i'\beta_i)}{1+\exp(x_i'\beta_i)},~i=1 ... N
\end{align}

The coefficients can be thought of as sensitivities to the covariates,
and they are distributed across the population of households following
a multivariate normal distribution with mean $\mu$ and covariance
$\Sigma$.   We assume that we know $\Sigma$, but we do not know $\mu$.
Instead, we place a multivariate normal prior on $\mu$, with mean $0$
and covariance $\Omega_0$.  Thus, each $\beta_i$, and $\mu$ are
$k-$dimensional vectors, and the total number of unknown variables in
the model is $(N+1)k$. 

In this model, we will make an assumption of \emph{conditional
independence} across households.   A household's purchase count $y_i$
depends on that households parameters $\beta_i$, but not the
parameters of any other household, $\beta_j$, conditional on other
population level parameters.  Since $\mu$ and $\Sigma$ depend on
$\beta_i$ for \emph{all} households, we cannot say that $y_i$ and $y_j$ are
truly independent.  A change in $\beta_i$ affects $\mu$ and
$\Sigma$, which in turn affect $\beta_j$ for some other household
$j$.  However, if we condition on $\mu$ and $\Sigma$, $y_i$ and $y_j$
would be independent.

This conditional independence assumption is what allows us to write
the joint likelihood of the data as a product of individual-level
probability models.  The log posterior density (LPD), ignoring any normalization constants, is
\begin{align}
  \log \pi(\beta_{1:N},\mu|Y, X, \Sigma_0,\Omega_0)=\sum_{i=1}^Np_i^{y_i}(1-p_i)^{T-y_i}
  -\frac{1}{2}\left(\beta_i-\mu\right)'\Sigma^{-1}\left(\beta_i-\mu\right)
-\frac{1}{2}\mu'\Omega_0^{-1}\mu
\end{align}

\subsection{Computing function values on sample data}

\subsubsection{Sample data and priors}

The package includes a simulated dataset for $N$ households and $k$
covariates per household.  A household makes $Y$ purchases out of $T$
opportunities.  The purchase probability for each household depends on
a covariate matrix $X$.  So let's start by loading the data (the name
of the data set is "binary"), and setting hyperprior values for $\Sigma^{-1}$ and $\Omega^{-1}$.

<<data>>= 
@ 


\subsubsection{LPD and gradient functions}

The function \func{binary.f} returns the log
posterior density of this model, evaluated at the vector passed as the
first argument.  This function takes two additional named arguments,
\funcarg{data} and \funcarg{priors}.  These two arguments are specific to this
example; in general, no additional arguments are required.  The
function funcarg{binary.grad} returns the gradient, and \funcarg{binary.hess} returns a
Hessian, in a sparse compressed format.  If you want to look more
closely at these functions, look at the \filename{R/binary.R} file in the package
source code.

So let's evaluate the LPD at a random "starting value."
 

<<startingVals>>=
@ 

\subsubsection{Using sparseHessianFD}

In practice, it is likely that you will not have a function
available that returns the Hessian (that is, there would be no
equivalent to \func{binary.hess}). Fortunately, hierarchical models
have Hessians with a predictable sparsity pattern.  You could write a
short code snippet that returns the row and column indices for your
particular problem.  Solely for the purposes of this example, we will
use the \func{binary.hess} function to compute the Hessian, and then
extract the sparsity pattern using the \func{Matrix.to.Coord} function from
the \pkg{sparseHessianFD} package.  The \func{tril} function sets all elements
not in the lower triangle of the matrix to zero. The \func{drop0}
function removes all zeros from the matrix, and returns a sparse
matrix as a \class{dgCMatrix} class.


<<hessStruct>>=
@ 

<<sparseHessianFD>>=
@ 

One advantage to using \class{sparseHessianFD} is that any
additional arguments that need to be passed to the LPD and gradient
functions are stored within the object.  The class also
contains member functions to return the objective function, gradient
and Hessian.  These member functions take only one argument, the
variable vector.  This means that we do not need to repeatedly pass
the data and prior arguments.  So now, we can compute the log
posterior density, gradient and Hessian as follows:


<<usingFD>>=
@ 

In Figure \ref{fig:hessUpperLeft}, we can see that the upper-left
  corner of the Hessian is sparse (the entire Hessian is too big to print).

\begin{figure}
<<hessUpperLeft, collapse=TRUE>>=
@ 
\caption{A sparse Hessian}\label{fig:hessUpperLeft}
\end{figure}

Here's a quick summary of what we did so far.where we are.

1.  We specified the model with a
function for the LPD, and one for its gradient. The first argument of these two functions must be a
variable vector.  Another other arguments must be named.

2.  We identified the row and column indices of the nonzero elements of the
Hessian of the LPD. In this case, we kind of "cheated" by using a
function that computes the Hessian exactly.  If such a function is not
available, one could generate a short loop to do the same thing.

3.  We constructed an object of class \class{sparseHessianFD} that contains
    functions that return the LPD, the gradient, and the sparse Hessian.


\subsubsection{Finding posterior mode}

Now it is time to find the posterior mode.  As discussed above, we
will use the \pkg{trustOptim} package, because it exploits the sparsity of
the Hessian of the objective function.  For the \funcarg{fn}, \funcarg{gr} and \funcarg{hs}
arguments, we provide the member functions of the FD object.  Details
on the control list are available in the \pkg{trustOptim} documentation.
The most important control option to mention here is that
\funcarg{function.scale.factor} must be positive for minimization, and
negative for maximization.

<<trustOptim>>=
@ 

The variable \code{post.mode} corresponds to $\theta^*$ in \citet{BraunDamien2015}.


\subsubsection{Defining proposal functions}

Next, we define a function to sample from a proposal density, and a
function to compute the log density of a proposal draw.  These
functions take a variable vector as the first argument, and list of
proposal parameters as the second argument.  As discussed above, the
functions in the \pkg{sparseMVN} package require two parameters:  a mean
vector, and a Cholesky decomposition of either the covariance or
precision matrix.  That means we need some wrapper functions.


<<defPropFuncs>>=
@ 

Next, we put the proposal parameters in a list. The proposal mean is
the posterior mean.  The proposal precision is the negative Hessian,
times a scaling factor.


<<propParams>>=
@ 


\subsubsection{Side note:  running the algorithm in parallel}

An advantage of BD over MCMC is that both proposal and posterior
samples can be generated in parallel.  There are a number of different
mechanisms available in R for running jobs in parallel.  One that I
think is easy to use requires the following setup.

<<parallelSetup>>=
@ 

This code allocates 12 processing cores to the parallel functions
below; use the number that is right for your system.  If you do not
want to run the code in parallel, change the flag to \code{run.par <-
FALSE}.


\subsubsection{Running the algorithm}
The next step in the BD algorithm is to simulate an empirical
approximation to the distribution of $\Phi(\theta|y)$ by sampling $M$
times from the proposal distribution, and computing
$\log\Phi(\theta|y)$ for each proposal sample.  Following the notation
in \citet{BraunDamien2015}, \variable{log.c1} is the log posterior density, and
\variable{log.c2} is the log of the proposal density, both evaluated at the
posterior mode.

This code uses the \func{aaply} function in the \pkg{plyr} package to compute
the LPD for each proposal draw.  This step will run in parallel if
\code{run.par == TRUE}.

<<proposals>>=
@ 

The last two lines in the previous code chunk are checks that
$\Phi(\theta|y)\leq 1$ for all of the proposal draws.  If not, then
the proposal distribution is invalid.  Make the proposal distribution
more diffuse by reducing the scaling factor on the negative Hessian,
and try again.

helpful hint:  Note that if $M$ is too low, there may not be enough draws to confirm
that the proposal distribution is indeed diffuse enough.  This can
cause problems later.  So don't try to make the proposal distribution
too "tight."


\subsubsection{Posterior draws}

 \emph{Finally} we can start sampling from the posterior density.  This
  code should run only if \funcarg{invalid.scale} is \variable{FALSE}.  Also, this step
  can be run in serial, or in parallel.  The idea behind the  parallel
  implementation is that samples are collected in batches. For
  example, suppose we need 100 posterior samples, and we have 5
  processing cores available.  We will run 5 instances of the
  sample.GDS function, each of which will generate 20 posterior draws
  as a batch.  We can then reassemble the output from the batches into
  a single result object.  If the number of batches exceeds the number
  of cores, some batches will wait until another batch is free.  The
  order of the draws does not matter.

  
<<sampleGDS>>=
@ 

Let's take a quick peak at the output list.

<<strDraws>>=
@ 

The \funcarg{draws} element has a posterior sample in each row.  The \funcarg{counts}
vector contains the number of proposal draws that were necessary to
accept that particular posterior draw.  This vector is needed to
compute the log marginal likelihood (LML, see below), and to assess
the efficiency of the algorithm.  The \funcarg{gt.1} vector flags whether a
threshold value was greater than 1.  This is an important check,
because if any elements of that vector are 1, that means that the
proposal density was still just a bit too tight.  If this is the case
for only a couple of draws, it's probably not a bug deal.  If it is
true for a large number of draws, not only is the proposal density
invalid, but something probably went wrong earlier in the algorithm.
Maybe $M$ was too small.

You can get summaries and quantiles for your parameters of interest in
the standard way.  In this case, let's just summarize the
population-level parameters.


<<summary, collapse=TRUE>>=
@ 


If any elements in \funcarg{counts} is NA, it means that the proposal count reached the
value in \funcarg{max.tries} without an acceptance.  This would suggest an inefficient sampler that
requires further investigation.

\subsubsection{Log marginal likelihood}

<<LML>>=
@ 




Before continuing, we want to explain why we have not provided a
``black box'' function that can run the entire BD algorithm at
once.  There are a few reasons for this.

\begin{enumerate}
\item Different tools may be better suited for
different models in different phases of the estimation algorithm.  For
example, a posterior distribution whose log density has a dense Hessian
may not need the functionality of \pkg{sparseHessianFD} or
\pkg{sparseMVN};
\item  In some of our other work, we found that
a focus on finding the posterior mode, before continuing on to the
other steps, has helped us diagnose other problems with the model
(e.g., ridges in the log posterior density surface);
\item Selecting a scaling factor on the Hessian at the posterior mode
  remains a manual adaptive process.  We do not yet have an optimal
  algorithm for that step; and
  \item We do not want to hide any problems with the algorithm that
    may arise under some kinds of models.
\end{enumerate}


We think that by splitting the algorithm into different phases, the
user will be able to better optimize the algorithm for the
characteristics of the model, and to more easily diagnose problems
when things go wrong.

\printbibliography

\end{document}
