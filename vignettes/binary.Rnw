\documentclass[10pt]{article}


%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Scalable estimation of hierarchical models}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{placeins} %% for \FloatBarrier
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{parskip}
\usepackage{setspace}
\linespread{1.2}

%%make knitr environment line spacing separate from LaTeX
\renewenvironment{knitrout}{\begin{singlespace}}{\end{singlespace}}



\DeclareMathOperator\logit{logit}
\DeclareMathOperator\Chol{Chol }
\DeclareMathOperator\cov{cov}

\newcommand{\pkg}[1]{\emph{#1}}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\func}[1]{\texttt{#1}}
\newcommand{\class}[1]{\texttt{#1}}
\newcommand{\funcarg}[1]{\texttt{#1}}
\newcommand{\filename}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\variable}[1]{\texttt{#1}}
\newcommand{\method}[1]{\textbf{#1}}

 \newcommand{\Prior}{\pi(\theta)}
 \newcommand{\Post}{\pi(\theta|y)}
 \newcommand{\Gtheta}{g(\theta)}
 \newcommand{\Phitheta}{\Phi(\theta|y)}
 \newcommand{\Ly}{\mathcal{L}(y)}
 \newcommand{\Dy}{\mathcal{D}(\theta,y)}


\usepackage[style=authoryear,%
			backend=biber,%
			maxbibnames=99,%
                        bibencoding=utf8,%
                        maxcitenames=1,
                        citetracker=true,
                        dashed=false,
                        maxalphanames=1,%
                        backref=false,%
			doi=false,%
			isbn=false,%
                        mergedate=basic,%
                        dateabbrev=true,%
                        natbib=true,%
                        uniquename=false,%
                        uniquelist=false,%
                        useprefix=true,%
                        firstinits=false
			]{biblatex}

 \addbibresource{/Users/braunm/OneDriveBusiness/References/Papers/braun_refs.bib}

 \setlength{\bibitemsep}{1em}
\AtEveryCitekey{\ifciteseen{}{\defcounter{maxnames}{2}}}
\DeclareFieldFormat[article,incollection,unpublished]{title}{#1} %No quotes for article titles
\DeclareFieldFormat[thesis]{title}{\mkbibemph{#1}} % Theses like book
                                % titles
\DeclareFieldFormat{pages}{#1} %% no pp prefix before page numbers
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{ % Don't print In: for journal articles
  \printtext{\bibstring{in}\intitlepunct}} %% but use elsewhere
}
\renewbibmacro*{volume+number+eid}{%
  \printfield{volume}%
  \printfield{number}%
  \setunit{\addcomma\addspace}%
  \printfield{eid}}

\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{date}{#1}
\AtEveryBibitem{\clearfield{day}}

\renewbibmacro*{issue+date}{% print month only
  \printtext{%
    \printfield{issue}\addspace%
    \newunit%
%\printtext{\printfield{month}}%
}
  \newunit}

\renewbibmacro*{publisher+location+date}{% no print year
  \printlist{location}%
  \iflistundef{publisher}
    {\setunit*{\addcomma\space}}
    {\setunit*{\addcolon\space}}%
  \printlist{publisher}%
  \setunit*{\addcomma\space}%
%%\printdate
  \newunit}

\renewcommand*{\nameyeardelim}{~} %no comma in cite
\renewcommand{\bibitemsep}{1ex}
\def\bibfont{\small}

\title{Estimating Bayesian Hierarchical Models using \pkg{bayesGDS}}
\author{Michael Braun\\Cox School of Business\\Southern Methodist University}
\date{March 18, 2015}

\begin{document}

\maketitle

<<setup1, echo=FALSE, cache=FALSE>>=
library(methods, quietly = TRUE)
library(bayesGDS, quietly = TRUE)
knitr::opts_chunk[["set"]](collapse = FALSE, eval=TRUE, echo=TRUE, comment = "#",
                           message=FALSE, tidy=FALSE, cache = TRUE) #
knitr::read_chunk("binary_chunks.R")
@


\citet{BraunDamien2015}, henceforth known as BD, introduce an
alternative to MCMC for sampling from posterior distributions. The
main advantages of BD over MCMC are
that samples can be collected in parallel, and that the algorithm
is scalable (linear complexity) for hierarchical models with conditionally independent
heterogeneous units.  These features make BD an attractive estimation method
for Bayesian hierarchical models of large datasets.

We assume that the reader is familiar with
the BD algorithm, and in particular, Algorithm 1.  In this note, we
discuss some of the practical issues involved in running the BD
algorithm. The focus is on a few specific aspects of the algorithm:
\begin{enumerate}
\item exploiting the sparsity of the Hessian of the log
  posterior density;
\item finding the posterior mode through nonlinear optimization;
 \item sampling from, and computing the log density of, a
   high-dimensional multivariate normal (MVN) distribution; and
 \item computing the log marginal likelihood of the data under the model.
\end{enumerate}

A common reaction to the BD algorithm, and especially to the need to find
the posterior mode, is ``easier said than done.''  We suspect that this reaction comes
from people who use existing \proglang{R} functions and packages that
are not particularly scalable.  Examples include using the \func{optim}
function in base \proglang{R} to find the posterior mode, or the
\func{rmvnorm} function in the \pkg{mvtnorm} package for sampling from
a multivariate normal (MVN) random variable.  These are functions with which
most \proglang{R} users are familiar, so it is understandable that the
barrier to adoption of algorithms that fail when using them would be high.

Fortunately, there are alternatives to \func{optim}, \func{rmvnorm},
and some other commonly used \proglang{R} functions, that are better
choices for running the BD algorithm on hierarchical models. These packages are listed in Table \ref{tab:packages}, and are
required to run the code in this vignette.  The \pkg{Matrix} and \pkg{sparseHessianFD} define
classes for working with sparse matrices, and the
\pkg{sparseMVN}, and \pkg{trustOptim} packages respectively provide sampling and
optimization routines that are designed to work with sparse matrices.
Those packages are not strictly necessary to use BD, but this package
(\pkg{bayesGDS}) implements only the rejection sampling phase.  The
\pkg{trustOptim}, \pkg{sparseHessianFD} and \pkg{sparseMVN} were
initially written as complements to \pkg{bayesGDS}, with the BD
algorithm in mind.


\begin{table}[htb]
  \centering
  \begin{tabular}{p{1.5in} p{3in} p{1in}}
    Package&Specific use for the BD algorithm&Relevant lines in
                                               Algorithm\\
\hline
    \pkg{Matrix}&Defines classes to store sparse matrices in a compressed
            format, and functions to work with, and to decompose,
            sparse matrices efficiently.&3, 11, 32\\
    \hline
    \pkg{sparseHessianFD}&For numerical estimation of sparse Hessians when
                     the gradient and sparsity pattern are both
                           known&Setup, 3, 11, 32\\
    \hline
    \pkg{sparseMVN}&Efficient functions to sample from, and to compute the
               log density of, a multivariate normal (MVN) random
               variable for which either the covariance or precision
               matrix is sparse. &11, 12, 32, 33\\
    \hline
    \pkg{trustOptim}&a package for nonlinear optimization that is efficient
                when the objective function has a sparse Hessian.&3\\
    \hline
    \pkg{bayesGDS} (this package)&Rejection sampling from target posterior, and
                    computing log marginal likelihood&20-37\\
    \hline
  \end{tabular}
  \caption{\proglang{R} packages that will be used in this note.}
  \label{tab:packages}
\end{table}



\section{Some background}

The goal is to sample a
parameter vector $\theta$ from a posterior density $\pi(\theta|y)$,
where $\pi(\theta)$ is the prior on $\theta$, $f(y|\theta)$ is the data
likelihood conditional on $\theta$, and $\mathcal{L}(y)$ is the marginal
likelihood of the data.  Let $\mathcal{D}(\theta,y)$ be the joint
density of the data and the parameters. Therefore,
\begin{align}
\pi(\theta|y)=\frac{f(y|\theta)\pi(\theta)}{\mathcal{L}(y)}=\frac{\mathcal{D}(\theta,y)}{\mathcal{L}(y)}
\end{align}

The model is fully specified by $\mathcal{D}(\theta,y)$, which is
equivalent to the posterior density, up to a normalizing constant $1/\Ly$.

If the heterogeneous units are conditionally independent, the data likelihood can be factored as

\begin{align}
f(y|\theta)=\prod_{i=1}^Nf_i\left(y_i|\beta_i,\alpha\right)
\end{align}

where $i$ indexes households. Each $y_i$ is a vector of observed data, each $\beta_i$ is a vector of
heterogeneous parameters, and $\alpha$ is a vector of homogeneous population-level
parameters.  The $\beta_i$ are distributed across the population of
households according to a mixing distribution $\pi(\beta_i|\alpha)$,
which also serves as the prior on each $\beta_i$.  The elements of $\alpha$
may influence either the household-level data likelihoods, or the
mixing distribution (or both).  In this example, $\theta$ includes all
$\beta_1\mathellipsis\beta_N$ and all elements of $\alpha$.

The prior itself can be factored as
\begin{align}
\pi(\theta)=\prod_{i=1}^N\pi_i(\beta_i|\alpha)\times\pi(\alpha).
\end{align}
Thus, the log posterior density is written as
\begin{align}
\log \pi(\beta,\alpha|y)&=\sum_{i=1}^N\left[\log f(y_i|\beta_i)+\log\pi(\beta_i|\alpha)\right]+\log\pi(\alpha)-\log\mathcal{L}(y)
\end{align}


\subsection{Sparse Hessians}\label{sec:sparseHessians}

An implication of the conditional independence
assumption is that the cross-partial derivatives of the unnormalized
log posterior density,
$\dfrac{\partial^2\log\Dy}{\beta_i\beta_j}$ are zero for all $i\neq
j$. As the number of households in the dataset increases, the number
of elements in the Hessian matrix increases quadratically, but the
number of \emph{non-zero} elements increases only linearly.  Thus, the
Hessian becomes sparser as the data set gets larger.

A sparse matrix is one that has a relatively small number of nonzero
elements.  A sparse matrix can be represented by only the nonzero
values, and the row and column indices of those values.  All of the
elements are known to be zero, so they do not need to be stored
explicitly.  Thus, the amount of memory required to store a sparse
matrix grows with the number of nonzero elements, as opposed to the
product of the number of rows and columns.  Also, linear algebra
operations are more efficient on compressed sparse matrices, because
operation on the nonzero elements can be ignored.  These computational
advantages come into play in nearly all of the steps of the BD
algorithm.  Although the sparsity of the Hessian of the log posterior
density is not a requirement for the BD algorithm, it is that sparsity
that makes the algorithm scalable \citep[Sec. 4]{BraunDamien2015}.

<<setup2, echo=FALSE>>=
@

As an example, suppose we have a hierarchical model with $N$ heterogeneous units,
each with a parameter vector of length $k$.  Also, assume that there
are $p$ population-level parameters or hyperparameters.

The \emph{sparsity pattern} of the Hessian depends on how the variables are
ordered within the vector. One such ordering is to group all of the
coefficients for each unit together.
\begin{align}
\beta_{11},...,\beta_{1k},\beta_{21},...,\beta_{2k},...~,~...~,~\beta_{N1}~,~...~,~\beta_{Nk},\mu_1,...,\mu_p
\end{align}

In this case, the Hessian has a "block-arrow" structure.  For example,
if $N=\Sexpr{NN}$, $k=\Sexpr{kk}$, and $p=\Sexpr{pp}$, then there are
\Sexpr{nv1} total variables, and the Hessian will have the sparsity
pattern in Figure \ref{fig:pattern1}.

Another option would be to group the coefficients by covariate.
\begin{align}
\beta_{11},...,\beta_{1N},\beta_{21},...,\beta_{2N},...,...,\beta_{k1},...,\beta_{kN},\mu_1,...,\mu_p
\end{align}

Now the Hessian has an "off-diagonal" sparsity pattern, as in Figure \ref{fig:pattern2}.

\begin{figure}
  \begin{subfigure}[t]{.5\linewidth}
<<pattern1, echo=FALSE>>==
@
\caption{A ``block-arrow'' sparsity pattern}\label{fig:pattern1}
\end{subfigure}
\begin{subfigure}[t]{.5\linewidth}
<<pattern2, echo=FALSE>>=
@
\caption{An ``off-diagonal'' sparsity pattern.}\label{fig:pattern2}
\end{subfigure}
\caption{Examples of sparsity patterns for a hierarchical model.  The
  pattern depends on the ordering of the coefficients. The
  \class{lgCMatrix} class is defined in the \pkg{Matrix} package.}
\end{figure}


In both cases, the number of non-zeros is the same.  There are
\Sexpr{nels1} elements in this symmetric matrix, but only  \Sexpr{nnz1} are
non-zero, and only \Sexpr{nnz1LT} values are unique.  Although in this
example the reduction in
RAM from using a sparse matrix structure for the Hessian may be
modest, consider what would happen if $N=\Sexpr{Q}$ instead.  In that case,
there are $\Sexpr{format(nv2, scientific=FALSE, big.mark=",")}$
variables in the problem, and more than $\Sexpr{floor(nels2/10^6)}$ million
elements in the Hessian.  However, only $\Sexpr{format(nnz2, scientific=FALSE, big.mark=",")}$ of those elements are
non-zero.  If we work with only the lower triangle of the Hessian we only need to work with
only $\Sexpr{format(nnz2LT, scientific=FALSE, big.mark=",")}$ values.


\subsection{Nonlinear optimization}\label{sec:optimization}

Finding the posterior mode $\theta^*$ can be a hard problem when there
is a high number of variables, especially when using standard
optimization routines, like the \func{optim} function in base
\proglang{R}, and others that are described in the CRAN Task View on
Optimization.  There are two common problems with these algorithms:

\paragraph{Premature termination}  Many algorithms apply a stopping rule that is based on
whether the optimizer is making "sufficient progress.'' If the
objective function does not improve by some minimum amount, the
algorithm believes that it has converged to a local optimum. This can happen before the gradient of the
objective function is sufficiently flat.  For an unconstrained objective
function, the \emph{only} appropriate stopping rule is whether a
function of the gradient (e.g., the Euclidean norm) is numerically
zero.  Any optimization routine that stops before that is stopping
prematurely, and the resulting normal approximations to the
posterior density would be invalid.

\paragraph{Poor scalability}   Search methods like Nelder-Mead (the default algorithm for
\func{optim}) are inefficient with a
massive number of parameters because the search space is large, and
they do not exploit information about slope and curvature to speed up
the time to convergence.  Conjugate gradient (\method{CG}) and
quasi-Newton (e.g., \method{BFGS}) do use
gradient information, with \method{BFGS} tracing out the curvature of
the function by using successive gradients to approximate the inverse
Hessian.  However, because \method{BFGS} stores the entire dense
inverse Hessian, its use is resource-intensive when the number of
parameters is large.   CG methods do not store the full Hessian
(or its inverse), so they can be more suited for large-scale
problems. However, like \method{BFGS}, they are not certain to
approximate the curvature of the objective function accurately at any
particular iteration, especially if the function is not convex \citep{R_trustOptim}.

A better choice of nonlinear optimizer would be one that uses exact calculations of the gradient and Hessian,
remains scalable for large problems, stops only when the norm of the
gradient is numerically zero, and is stable when passing through
regions in which the surface of the objective function is flat.  The \func{trust.optim} function
in the \pkg{trustOptim} package meets those criteria.
\Citet{R_trustOptim} describes the many advantages of the
\func{trust.optim} function.  Two advantages of note are:

\begin{enumerate}
\item convergence only when the norm of the
  gradient is sufficiently close to zero; and
\item the ability to use exact Hessian information that is stored as a
  compressed sparse matrix.
\end{enumerate}

The \func{trust.optim} function supports three optimization routines:
two quasi-Newton methods (\method{SR1} and \method{BFGS}; see
\citet{NocedalWright2006}), and \method{Sparse} method.  All three
methods require the user to supply a function that returns the value
of the objective function, \emph{and} a function that returns the
gradient.  The \method{Sparse} method requires an additional function
that returns the Hessian as a \class{dgCMatrix} object.  The
\class{dgCMatrix} class is defined in the \pkg{Matrix} package, and is
one of several classes for the storage of, and operation on, sparse matrices.


\subsection{Computing derivatives}\label{sec:derivatives}


Nearly all reasonable choices of a nonlinear optimization algorithm
require the user to provide a the gradient of the objective function.
The \method{Sparse} method for \func{trust.optim} requires the Hessian as well.  The Hessian is
also required to approximate the posterior density with a MVN
distribution around the posterior mode.

For the purposes of the BD algorithm, there are two "good" ways to
compute a derivative. The first is to derive
it analytically, and write a function to compute it.  This approach is straightforward, but it can be tedious and
error-prone for complicated models.

The second is to use automatic,
or algorithmic, differentiation (AD).  In short, AD generates
code for the derivative by applying the chain rule on the same sequence of operations
that computes the objective function.  There are a number of different approaches to
implementing AD, and AD libraries are available for
many programming languages.  However, as of now, there are none for \proglang{R} that are
well-suited for a general class of Bayesian hierarchical models.  For
\proglang{R} users, we believe that coding the objective function in \proglang{C++} using the
\pkg{CppAD} library, and interfacing with \proglang{R} using \pkg{Rcpp}, is the best option
at the moment.  How to do this will be the subject of a future
vignette.  What matters is that functions that return the gradient and
Hessian of the log posterior density are available, and that they are sufficiently
accurate.  The advantage of both analytic and AD derivatives is that they are ``exact.''

We do not recommend estimating the gradient by numerical approximation via finite
differencing (FD).  FD involves computing
$\dfrac{\partial f}{\partial x_j}\approx\dfrac{f(x_j+h)-f(x_j)}{h}$,
or some variation thereof, for each of the $j=1...J$ variables,
using an arbitrarily small $h$ as a ``perturbation factor.''  As $h\rightarrow 0$, this estimated
difference approaches the gradient.  Not only are FD methods are highly vulnerable
to numerical precision problems, but the complexity of the method
grows with the number of variables   Thus, FD is not a reasonable
option for estimating the gradient
when the number of variables is large.  The time to compute the
gradient using AD, on the
other hand, is only a small fixed multiple of the time to compute the
objective function, regardless of the number of variables
\citep{GriewankWalther2008}.

The computational cost of computing a dense Hessian using FD is
quadratic in the number of variables, and the numerical precision
problems are even more pronounced than for a gradient.  Nevertheless,
one can use FD to estimate the Hessian if the Hessian is sparse, \emph{and} the
sparsity pattern is known in advance, \emph{and} the gradient is
exact (either derived analytically or computed using AD).  The
\pkg{sparseHessianFD} package defines an \proglang{R} class for doing
this (the algorithms are based on \citet{ColemanGarbow1985} and
\citet{ColemanGarbow1985b}). An object
of class \class{sparseHessianFD} is constructed from
functions that return the value of the log density and its gradient; any additional
arguments that are passed to these functions; and the row
and column indices of the non-zero elements of the lower triangle of
the Hessian.  The \class{sparseHessianFD} object contains member
functions not only for the log density and the gradient, but also for
the sparse Hessian, as a \class{dgCMatrix}
object.  See the \pkg{sparseHessianFD} documentation and vignette for
more details.

The \class{sparseHessianFD} class is useful for
hierarchical models because the
sparsity pattern of a hierarchical model is often predictable.
Even if the Hessian were derived analytically, it still may be faster
to use \class{sparseHessianFD} for
repeated estimation, because of the way the package exploits sparsity.  Given the typical sparsity pattern of a hierarchical model, the time to estimate
a Hessian using \pkg{sparseHessianFD} does not grow with the number of
heterogeneous units, making it a scalable way of
estimating sparse Hessians for large datasets.

The trade-off from using the \pkg{sparseHessianFD} package is that the
Hessian is still a numerical approximation.  We cannot guarantee that
this approximation is "good enough" for all cases.  However, the
performance of an optimization algorithm is likely to be more sensitive to
numerical imprecision in the gradient than in the Hessian. Thus, we
are comfortable working with finite-differenced sparse Hessians, even though
we will not use finite-differenced gradients.  This approach will
almost certainly fail if the gradient itself is estimated using FD.
In that case, the estimate of the Hessian would be a finite difference of finite
differences, with too much numerical imprecision to be of much
value.


\subsection{High-dimensional MVN distribution}\label{sec:MVN}

Another potential source of poor scalability is in sampling from, and
computing the log density of, a multivariate normal (MVN)
distribution. The \func{rmvnorm} and \func{dmvnorm} functions in the
\pkg{mvtnorm} package are inefficient
in the context of the BD algorithm for three reasons.

\begin{enumerate}
\item They require the covariance matrix as one of the arguments, meaning that
the negative Hessian must be inverted explicitly.
\item They do not
exploit the sparsity of the Hessian for computational gain; and
\item The \func{rmvnorm} and \func{dmvnorm} functions factor the
  covariance matrix every time the function is called, even if the matrix has not changed.
\end{enumerate}

The \pkg{sparseMVN} package addresses these issues.  The \func{rmvn.sparse} and
\func{dmvn.sparse} functions take, as one of the arguments, the Cholesky
decomposition of either a sparse covariance or sparse precision
matrix.  Thus, the user can use either the covariance
or precision matrix, depending on which is more convenient.  The
Cholesky decomposition is provided as a \class{Cholesky} object, which
is a sparse, compressed representation that is defined in the \pkg{Matrix} package. Since the size
of the sparse Hessian grows only linearly with the size of the
dataset, the \pkg{sparseMVN} package is a scalable alternative for working
with an MVN.  More details are available in the \pkg{sparseMVN}
documentation and vignette, as well as in the example in \ref{sec:runAlgorithm}.

\section{Example:  hierarchical binary choice}\label{sec:example}

Before going into the details of how to put all of the pieces of the
BD algorithm together, let's
consider the following example of a log posterior density function
with a sparse Hessian.
 Suppose we have a dataset of $N$ households, each with $T$
 opportunities to purchase a particular product.  Let $y_i$ be the
 number of times household $i$ purchases the product, out of the $T$
 purchase opportunities.  Furthermore, let $p_i$ be the probability of
 purchase; $p_i$ is the same for all $T$ opportunities, so we can treat $y_i$ as a binomial random variable.  The purchase probability
 $p_i$ is heterogeneous, and depends on both $k$ continuous covariates
 $x_i$, and a heterogeneous coefficient vector $\beta_i$, such that
\begin{align}
  p_i=\frac{\exp(x_i'\beta_i)}{1+\exp(x_i'\beta_i)},~i=1 ... N
\end{align}

The coefficients can be thought of as sensitivities to the covariates,
and they are distributed across the population of households following
a multivariate normal distribution with mean $\mu$ and covariance
$\Sigma$.   We assume that we know $\Sigma$, but we do not know $\mu$.
Instead, we place a multivariate normal prior on $\mu$, with mean $0$
and covariance $\Omega_0$.  Thus, each $\beta_i$, and $\mu$ are
$k-$dimensional vectors, and the total number of unknown variables in
the model is $(N+1)k$.

In this model, we will make an assumption of \emph{conditional
independence} across households.   A household's purchase count $y_i$
depends on that household's $\beta_i$, but not the
parameters of any other household, $\beta_j$, conditional on other
population level parameters.  Since $\mu$ and $\Sigma$ depend on
$\beta_i$ for \emph{all} households, we cannot say that $y_i$ and $y_j$ are
truly independent.  A change in $\beta_i$ affects $\mu$ and
$\Sigma$, which in turn affect $\beta_j$ for some other household
$j$.  However, if we condition on $\mu$ and $\Sigma$, then $y_i$ and $y_j$
are independent, so we describe the data likelihoods as conditionally independent.

This conditional independence assumption is what allows us to write
the joint likelihood of the data as a product of individual-level
probability models.  Therefore, the log posterior density, ignoring any normalization constants, is
\begin{align}
  \log \pi(\beta_{1:N},\mu|Y, X, \Sigma_0,\Omega_0)=\sum_{i=1}^Np_i^{y_i}(1-p_i)^{T-y_i}
  -\frac{1}{2}\left(\beta_i-\mu\right)'\Sigma^{-1}\left(\beta_i-\mu\right)
-\frac{1}{2}\mu'\Omega_0^{-1}\mu
\end{align}

\subsection{Computing function values on sample data}

\subsubsection{Functions, sample data, and priors for the example}

The \pkg{bayesGDS} package includes a simulated dataset for $N$ households and $k$
covariates per household.  A household makes $Y$ purchases out of $T$
opportunities.  The purchase probability for each household depends on
a covariate matrix $X$.  So let's start by loading the data (the name
of the data set is "binary"), and setting hyperprior values for $\Sigma^{-1}$ and $\Omega^{-1}$.

<<data>>=
@


The function \func{binary.f} returns the unnormalized log
posterior density of this model, $\log\Dy$, evaluated at the vector passed as the
first argument.  This function takes two additional named arguments,
\funcarg{data} and \funcarg{priors}.  The
function \funcarg{binary.grad} returns the gradient, and \funcarg{binary.hess} returns a
Hessian, in a sparse compressed format.


<<startingVals>>=
@

\subsubsection{Using sparseHessianFD when the Hessian is unknown}

Hessians can be difficult to derive analytically, but Hessians for hierarchical models
have predictable sparsity patterns. The
\pkg{sparseHessianFD} package simplifies numerical approximation of a
sparse Hessian, and should be used if exact
methods are unavailable (see Section \ref{sec:derivatives}.   The
\func{sparseHessianFD.new} function is a wrapper around the
constructor for the \class{sparseHessianFD} class, and returns an
object of that class.  But before calling \func{sparseHessianFD.new},
we need to get the sparsity pattern of the lower triangle of the
Hessian. The sparsity pattern is defined
by integer vectors of the row and column indices of the nonzero elements.

A straightforward
way to generate the sparsity pattern is to build a sparse integer or logical matrix,
and then use the \func{Matrix.to.Coord} function from
\pkg{sparseHessianFD}.  The \func{Matrix.to.Coord} function returns a
list of two integer vectors that can be passed to \func{sparseHessianFD.new}.

<<hessStruct>>=
@

Now we can construct the \class{sparseHessianFD} object.

<<sparseHessianFD>>=
@

One advantage to using \class{sparseHessianFD} is that any
additional arguments that need to be passed to the objective function are stored within the object. This means that we do not need to repeatedly pass
the data and prior arguments.  So now, we can compute the log
posterior density, gradient and Hessian as follows:

<<usingFD>>=
@

In Figure \ref{fig:hessUpperLeft}, we can see that the upper-left
  corner of the Hessian is sparse (the entire Hessian is too big to
  print).  We can also confirm that \code{FD[["hessian"]]} returns the
  same matrix as \code{binary.hess}.

\begin{figure}
<<hessUpperLeft, collapse=TRUE>>=
@
\caption{A sparse Hessian}\label{fig:hessUpperLeft}
\end{figure}


\section{Running the algorithm}\label{sec:runAlgorithm}

Now it's time to estimate the posterior distributions of the model parameters.

\subsubsection{Finding posterior mode}

We use the \pkg{trustOptim} package, because it exploits the sparsity of
the Hessian of the objective function, and it uses the gradient of the
objective function to determine when it has converged to a local
optimum.  For the \funcarg{fn}, \funcarg{gr} and \funcarg{hs}
arguments, we provide the member functions of the FD object.  Details
on the control list are available in the \pkg{trustOptim} documentation.
The most important control option to mention here is that
\funcarg{function.scale.factor} must be positive for minimization, and
negative for maximization.

<<trustOptim>>=
@


\subsubsection{Defining proposal functions}

Next, we define a function to sample from a proposal density, and a
function to compute the log density of a proposal draw.  These
functions take a variable vector as the first argument, and list of
proposal parameters as the second argument.  As discussed in Section \ref{sec:MVN}, the
functions in the \pkg{sparseMVN} package require two parameters:  a mean
vector, and a Cholesky decomposition of either the covariance or
precision matrix.  That means we need some wrapper functions.


<<defPropFuncs>>=
@

Next, we put the proposal parameters in a list. The proposal mean is
the posterior mean.  The proposal precision is the negative Hessian,
times a scaling factor.


<<propParams>>=
@


\subsubsection{Side note:  running the algorithm in parallel}

An advantage of BD over MCMC is that both proposal and posterior
samples can be generated in parallel.  There are a number of different
mechanisms available in \proglang{R} for running jobs in parallel.  One that I
think is easy to use is based on the \pkg{parallel} package.  In the
next code chunk, I allocate 10 cores for parallel processing, and set
a random seed for simulating random variables (more on that later).
If you do not want to run the code in parallel, change the flag to
\code{run.par <- FALSE}.  This will change the number of allocated
cores to 1.

<<parallelSetup>>=
@




\subsubsection{Estimating density of threshold values}
The next step in the BD algorithm is to simulate an empirical
approximation to the cumulative distribution of $\Phi(\theta|y)$.  We sample $M$
times from the proposal distribution, and compute
$\log\Phi(\theta|y)$ for each proposal sample.  Following the notation
in \citet{BraunDamien2015}, \variable{log.c1} is the log posterior density, and
\variable{log.c2} is the log of the proposal density, both evaluated at the
posterior mode $\theta^*$.

The next code chunk uses the \func{aaply} function from the \pkg{plyr} package to compute
the log posterior density for each proposal draw.  This step will run in parallel if
\code{run.par == TRUE}.

<<proposals>>=
@

The last two lines in the previous code chunk are checks that
$\Phi(\theta|y)\leq 1$ for all of the proposal draws.  If the check fails, then
the proposal distribution is invalid.  Make the proposal distribution
more diffuse by reducing the scaling factor on the negative Hessian,
and try again.

Helpful hint:  If $M$ is too low, there may not be enough proposal draws to confirm
that the proposal distribution is sufficiently diffuse.  This can
cause problems later.  So don't try to make the proposal distribution
too "tight."  We think that time invested in ``optimizing'' the
proposal distribution is not a well-used resource.


\subsubsection{Posterior draws via rejection sampling}

 \emph{Finally} we can start sampling from the posterior density,
 using functions in the \pkg{bayesGDS} package.  We should proceed to
 this step only if \code{valid.scale==TRUE}.

 The \func{sample.GDS} function is the ``workhorse'' function of
 \pkg{bayesGDS}.  Although the main advantage of the BD algorithm is
 parallel sampling, each call to \func{bayes.GDS} uses only 1 core.
 Thus, the argument \funcarg{n.draws} is the number of draws for that
 particular call to \func{sample.GDS}. The other required arguments to
 \func{sample.GDS} are the $M$-length vector of $\log\Phi(\theta|y)$,
 the posterior mode $\theta^*$; the function that returns the log
 posterior density; the functions that sample from, and compute the
 log density of, the proposal distribution; parameters of the proposal distribution.

 The \func{sample.GDS} function also takes some control parameters,
 such as how often the algorithm should give a status report; a
 \funcarg{thread.id} (useful for reporting); whether
 the algorithm should \funcarg{announce} when a posterior sample is
 accepted; and a starting random seed for that \func{sample.GDS} call.

 If \func{sample.GDS} is run only once, then \funcarg{thread.id} will
 default to 1, and \funcarg{seed} can be anything you want.  However,
 if running \func{sample.GDS} for multiple batches, each starting seed
 needs to be different.  In this example, we use the \func{foreach}
 function to create \variable{n.batch} instances of \func{sample.GDS},
 each of which is executed on a different processing core in parallel
 with the others.  After all parallel runs of \func{sample.GDS} are
 complete, we use a Map-Reduce construct to merge the results together
 into a single output list.


 The next code chunk shows the code for both parallel and serial
 implementations.  In both cases, we want to collect
 \variable{n.draws} total posterior samples.  The algorithm will give
 up after \variable{max.tries} proposals for a single draw (to keep
 the algorithm from running forever).  For the parallel
 implementation, the batch size is the number of samples that each
 instance of \func{sample.GDS} will collect.  Thus, the number of
 batches \variable{n.batch} is the total number of draws needed, divided by the number of
 draws in each batch.  In this example, we collect 20 total draws
 using 10 cores, with each core responsible for 2 draws.  The order in
 which the batches are returned does not matter.

<<sampleGDS>>=
@

\subsubsection{The output}

Let's take a quick peak at the output list.

<<strDraws>>=
@

The \funcarg{draws} element has a posterior sample in each row.  Each
column is a variable.  The \funcarg{counts}
vector contains the number of proposal draws that were necessary to
accept that particular posterior draw.  This vector is needed to
compute the log marginal likelihood (LML, see below), and to assess
the efficiency of the algorithm.  The \funcarg{gt.1} vector flags whether a
threshold value was greater than 1.  This is an important check,
because if any elements of that vector are 1, that means that the
proposal density was still just a bit too tight.  If this is the case
for only a couple of draws, it's probably not a big deal.  If it is
true for a large number of draws, not only is the proposal density
invalid, but something probably went wrong earlier in the algorithm.
Maybe $M$ was too small.

You can get summaries and quantiles for your parameters of interest in
the standard way.  In this case, let's just summarize the
population-level parameters.


<<summary, collapse=TRUE>>=
@


If any elements in \funcarg{counts} is NA, it means that the proposal count reached the
value in \funcarg{max.tries} without an acceptance.  This would suggest an inefficient sampler that
requires further investigation.

\subsubsection{Log marginal likelihood}


The log marginal likelihood (LML) is the likelihood of the data under
the model, $\Ly$.  For better or worse, the LML is often used for model comparison (e.g.,
computing Bayes factors).  As discussed in \citet{BraunDamien2015},
there is no generally accepted method for computing the LML from MCMC
output.  However, estimating the LML using the \func{LML} function in
this package is straightforward.  All of the arguments to \func{LML}
were used in earlier function calls, or returned by \func{sample.GDS}.


<<LML>>=
@


\section{Future development}

The \pkg{bayesGDS} package remains incomplete.  Here are some
improvements and enhancements that I am considering for future releases.

Before continuing, we want to explain why we have not provided a
``black box'' function that can run the entire BD algorithm at
once.  There are a few reasons for this.

\begin{enumerate}
\item Different tools may be better suited for
different models in different phases of the estimation algorithm.  For
example, a posterior distribution whose log density has a dense Hessian
may not need the functionality of \pkg{sparseHessianFD} or
\pkg{sparseMVN};
\item  In some of our other work, we found that
a focus on finding the posterior mode, before continuing on to the
other steps, has helped us diagnose other problems with the model
(e.g., ridges in the log posterior density surface);
\item Selecting a scaling factor on the Hessian at the posterior mode
  remains a manual adaptive process.  We do not yet have an optimal
  algorithm for that step; and
  \item We do not want to hide any problems with the algorithm that
    may arise under some kinds of models.
\end{enumerate}


We think that by splitting the algorithm into different phases, the
user will be able to better optimize the algorithm for the
characteristics of the model, and to more easily diagnose problems
when things go wrong.

\printbibliography

\end{document}
