\documentclass[10pt]{article}


%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Scalable estimation of hierarchical models}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathpazo}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[margin=1.5in]{geometry}
\usepackage{placeins} %% for \FloatBarrier
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{parskip}
\usepackage{setspace}
\linespread{1.1}

%%make knitr environment line spacing separate from LaTeX
\renewenvironment{knitrout}{\begin{singlespace}}{\end{singlespace}}



\DeclareMathOperator\logit{logit}
\DeclareMathOperator\Chol{Chol }
\DeclareMathOperator\cov{cov}

\newcommand{\pkg}[1]{\emph{#1}}
\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\func}[1]{\texttt{#1}}
\newcommand{\class}[1]{\texttt{#1}}
\newcommand{\funcarg}[1]{\texttt{#1}}
\newcommand{\filename}[1]{\textit{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\variable}[1]{\texttt{#1}}
\newcommand{\method}[1]{\textbf{#1}}

 \newcommand{\Prior}{\pi(\theta)}
 \newcommand{\Post}{\pi(\theta|y)}
 \newcommand{\Gtheta}{g(\theta)}
 \newcommand{\Phitheta}{\Phi(\theta|y)}
 \newcommand{\Ly}{\mathcal{L}(y)}
 \newcommand{\Dy}{\mathcal{D}(\theta,y)}


\usepackage[style=authoryear,%
			backend=biber,%
			maxbibnames=99,%
                        bibencoding=utf8,%
                        maxcitenames=1,
                        citetracker=true,
                        dashed=false,
                        maxalphanames=1,%
                        backref=false,%
			doi=false,%
			isbn=false,%
                        mergedate=basic,%
                        dateabbrev=true,%
                        natbib=true,%
                        uniquename=false,%
                        uniquelist=false,%
                        useprefix=true,%
                        firstinits=false
			]{biblatex}

%%\addbibresource{/Users/braunm/OneDriveBusiness/References/Papers/braun_refs.bib}
 \addbibresource{/Users/mbraun92/OneDriveBusiness/References/Papers/braun_refs.bib}

 \setlength{\bibitemsep}{1em}
\AtEveryCitekey{\ifciteseen{}{\defcounter{maxnames}{2}}}
\DeclareFieldFormat[article,incollection,unpublished]{title}{#1} %No quotes for article titles
\DeclareFieldFormat[thesis]{title}{\mkbibemph{#1}} % Theses like book
                                % titles
\DeclareFieldFormat{pages}{#1} %% no pp prefix before page numbers
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{ % Don't print In: for journal articles
  \printtext{\bibstring{in}\intitlepunct}} %% but use elsewhere
}
\renewbibmacro*{volume+number+eid}{%
  \printfield{volume}%
  \printfield{number}%
  \setunit{\addcomma\addspace}%
  \printfield{eid}}

\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{date}{#1}
\AtEveryBibitem{\clearfield{day}}

\renewbibmacro*{issue+date}{% print month only
  \printtext{%
    \printfield{issue}\addspace%
    \newunit%
%\printtext{\printfield{month}}%
}
  \newunit}

\renewbibmacro*{publisher+location+date}{% no print year
  \printlist{location}%
  \iflistundef{publisher}
    {\setunit*{\addcomma\space}}
    {\setunit*{\addcolon\space}}%
  \printlist{publisher}%
  \setunit*{\addcomma\space}%
%%\printdate
  \newunit}

\renewcommand*{\nameyeardelim}{~} %no comma in cite
\renewcommand{\bibitemsep}{1ex}
\def\bibfont{\small}

\title{Estimating Bayesian Hierarchical Models using \pkg{bayesGDS}}
\author{Michael Braun\\Cox School of Business\\Southern Methodist University}
\date{March 18, 2015}

\begin{document}

\maketitle

\begin{abstract}
This note is a ``practitioner's guide'' to estimating Bayesian
hierarchical models using the sampling algorithm in
\citet{BraunDamien2015}.  The \pkg{bayesGDS} package for \proglang{R}
provides functions for running the rejection sampling phase of the
algorithm.  Three other packages, \pkg{trustOptim}, \pkg{sparseMVN}
and \pkg{sparseHessianFD}, are also discussed, and are used in the
example.  These packages are generally useful for problems with sparse
Hessians, but were written with the \citet{BraunDamien2015} algorithm
in mind.
\end{abstract}
\vspace{1em}

<<setup1, echo=FALSE, cache=FALSE>>=
library(methods, quietly = TRUE)
library(bayesGDS, quietly = TRUE)
knitr::opts_chunk[["set"]](collapse = FALSE, eval=TRUE, echo=TRUE, comment = "#",
                           message=FALSE, tidy=FALSE, cache = TRUE) #
knitr::read_chunk("binary_chunks.R")
@

\citet{BraunDamien2015}, henceforth known as BD, introduce an
alternative to MCMC for sampling from posterior distributions. The
main advantages of BD over MCMC are
that samples can be collected in parallel, and that the algorithm
is scalable (linear complexity) for hierarchical models with conditionally independent
heterogeneous units.  These features make BD an attractive estimation method
for Bayesian hierarchical models of large datasets.

We assume that the reader is familiar with
the BD algorithm.  In this note, we
discuss some of the practical issues of implementation, and how to run
the algorithm using a suite of \proglang{R} packages. The focus is on a few specific aspects of the algorithm:
\begin{enumerate}
\item How the sparsity of the Hessian of the log
  posterior density makes the algorithm scalable.
\item Efficient nonlinear optimization for finding the posterior mode.
 \item Sampling from, and computing the log density of, a
   high-dimensional multivariate normal (MVN) distribution.
 \item Estimating the log marginal likelihood of the data under the model.
\end{enumerate}

A common reaction to the BD algorithm, and especially to the need to find
the posterior mode, is ``easier said than done.''  We suspect that this reaction comes
from experience with existing \proglang{R} functions and packages that
are not particularly scalable.  Examples include the \func{optim}
function in base \proglang{R}, and the \pkg{mvtnorm} package for sampling from
a multivariate normal (MVN) random variable.  These are functions and packages with which
most \proglang{R} users are familiar, so it is understandable that the
barrier to adoption of algorithms that fail when using them would be high.

Fortunately, there are better alternatives for running the BD algorithm on hierarchical models. These packages are listed in Table \ref{tab:packages}, and are
required to run the code in this vignette.  The \pkg{Matrix} and \pkg{sparseHessianFD} define
classes for working with sparse matrices.  The
\pkg{sparseMVN} and \pkg{trustOptim} packages respectively provide sampling and
optimization routines that are designed to work with sparse matrices.
The (\pkg{bayesGDS}) implements the rejection sampling phase of the BD
algorithm.  The \pkg{trustOptim}, \pkg{sparseHessianFD} and \pkg{sparseMVN} were
written as complements to \pkg{bayesGDS}, with the BD
algorithm in mind.


\begin{table}[htb]
  \centering
  \begin{tabular}{p{1.5in} p{3in} p{1in}}
    Package&Specific use for the BD algorithm&Relevant lines in
                                               BD Algorithm 1\\
\hline
    \pkg{Matrix}&Defines classes to store sparse matrices in a compressed
            format, and functions to work with, and to decompose,
            sparse matrices efficiently.&3, 11, 32\\
    \hline
    \pkg{sparseHessianFD}&For numerical estimation of sparse Hessians when
                     the gradient and sparsity pattern are both
                           known&Setup, 3, 11, 32\\
    \hline
    \pkg{sparseMVN}&Efficient functions to sample from, and to compute the
               log density of, a multivariate normal (MVN) random
               variable for which either the covariance or precision
               matrix is sparse. &11, 12, 32, 33\\
    \hline
    \pkg{trustOptim}&a package for nonlinear optimization that is efficient
                when the objective function has a sparse Hessian.&3\\
    \hline
    \pkg{bayesGDS} (this package)&Rejection sampling from target posterior, and
                    computing log marginal likelihood&20-37\\
    \hline
  \end{tabular}
  \caption{\proglang{R} packages that will be used in this note.}
  \label{tab:packages}
\end{table}



\section{Some background}

As explained in \citet{BraunDamien2015}, the goal is to sample a
parameter vector $\theta$ from a posterior density $\pi(\theta|y)$,
where $\pi(\theta)$ is the prior on $\theta$, $f(y|\theta)$ is the data
likelihood conditional on $\theta$, and $\mathcal{L}(y)$ is the marginal
likelihood of the data.  Let $\mathcal{D}(\theta,y)$ be the joint
density of the data and the parameters. Therefore,
\begin{align}
\pi(\theta|y)=\frac{f(y|\theta)\pi(\theta)}{\mathcal{L}(y)}=\frac{\mathcal{D}(\theta,y)}{\mathcal{L}(y)}
\end{align}

The model is fully specified by $\mathcal{D}(\theta,y)$, which is
equivalent to the posterior density, up to a normalizing constant $1/\Ly$.

If the heterogeneous units are conditionally independent, the data likelihood can be factored as
\begin{align}
f(y|\theta)=\prod_{i=1}^Nf_i\left(y_i|\beta_i,\alpha\right)
\end{align}

where $i$ indexes households. Each $y_i$ is a vector of observed data, each $\beta_i$ is a vector of
heterogeneous parameters, and $\alpha$ is a vector of homogeneous population-level
parameters.  The $\beta_i$ are distributed across the population of
households according to a mixing distribution $\pi(\beta_i|\alpha)$,
which also serves as the prior on each $\beta_i$.  The elements of $\alpha$
may influence either the household-level data likelihoods, or the
mixing distribution (or both).  In this example, $\theta$ includes all
$\beta_1\mathellipsis\beta_N$ and all elements of $\alpha$.

The prior itself can be factored as
\begin{align}
\pi(\theta)=\prod_{i=1}^N\pi_i(\beta_i|\alpha)\times\pi(\alpha).
\end{align}
Thus, the log posterior density is written as
\begin{align}
\log \pi(\beta,\alpha|y)&=\sum_{i=1}^N\left[\log f(y_i|\beta_i)+\log\pi(\beta_i|\alpha)\right]+\log\pi(\alpha)-\log\mathcal{L}(y)
\end{align}


\subsection{Sparse Hessians}\label{sec:sparseHessians}

A sparse matrix is one that has a relatively small number of non-zero
elements, and can be fully represented by only the
values, and the row and column indices, of the non-zeros.  The zeros do not need to be stored
explicitly.  Thus, the amount of memory required to store a sparse
matrix grows with the number of non-zero elements, as opposed to the
product of the number of rows and columns.  Matrix
operations are more efficient on compressed sparse matrices, because
operation on the non-zero elements can be ignored.  These computational
advantages come into play in nearly all of the steps of the BD
algorithm.  Although a sparse Hessian is not a requirement for the BD algorithm, it is that sparsity that makes the algorithm scalable \citep[Sec. 4]{BraunDamien2015}.

An implication of the conditional independence
assumption is that the cross-partial derivatives of the unnormalized
log posterior density,
$\dfrac{\partial^2\log\Dy}{\beta_i\beta_j}$, are zero for all $i\neq
j$. As the number of households in the dataset increases, the number of elements in the Hessian matrix increases quadratically, but the
number of \emph{non-zero} elements increases only linearly.  Thus, the
Hessian becomes sparser as the data set gets larger.

<<setup2, echo=FALSE>>=
@

As an example, suppose we have a hierarchical model with $N$ heterogeneous units,
each with a parameter vector of length $k$.  Also, assume that there
are $p$ population-level parameters or hyperparameters.

The \emph{sparsity pattern} of the Hessian depends on how the variables are
ordered within the vector. One such ordering is to group all of the
coefficients for each unit together.
\begin{align}
\beta_{11},...,\beta_{1k},\beta_{21},...,\beta_{2k},...~,~...~,~\beta_{N1}~,~...~,~\beta_{Nk},\mu_1,...,\mu_p
\end{align}

In this case, the Hessian has a "block-arrow" structure.  For example,
if $N=\Sexpr{NN}$, $k=\Sexpr{kk}$, and $p=\Sexpr{pp}$, then there are
\Sexpr{nv1} total variables, and the Hessian will have the sparsity
pattern in Figure \ref{fig:pattern1}.

Another option would be to group the coefficients by covariate.
\begin{align}
\beta_{11},...,\beta_{1N},\beta_{21},...,\beta_{2N},...,...,\beta_{k1},...,\beta_{kN},\mu_1,...,\mu_p
\end{align}

Now the Hessian has an "off-diagonal" sparsity pattern, as in Figure \ref{fig:pattern2}.

\begin{figure}
  \begin{subfigure}[t]{.5\linewidth}
<<pattern1, echo=FALSE>>==
@
\caption{A ``block-arrow'' sparsity pattern}\label{fig:pattern1}
\end{subfigure}
\begin{subfigure}[t]{.5\linewidth}
<<pattern2, echo=FALSE>>=
@
\caption{An ``off-diagonal'' sparsity pattern.}\label{fig:pattern2}
\end{subfigure}
\caption{Examples of sparsity patterns for a hierarchical model.  The
  pattern depends on the ordering of the coefficients. The
  \class{lgCMatrix} class is defined in the \pkg{Matrix} package.}
\end{figure}


In both cases, the number of non-zeros is the same.  There are
\Sexpr{nels1} elements in this symmetric matrix, but only  \Sexpr{nnz1} are
non-zero, and only \Sexpr{nnz1LT} values are unique.  Now consider what would happen if $N=\Sexpr{Q}$ instead.  In that case,
there are $\Sexpr{format(nv2, scientific=FALSE, big.mark=",")}$
variables in the problem, and more than $\Sexpr{floor(nels2/10^6)}$ million
elements in the Hessian.  However, only $\Sexpr{format(nnz2, scientific=FALSE, big.mark=",")}$ of those elements are
non-zero.  If we work with only the lower triangle of the Hessian we only need to work with
only $\Sexpr{format(nnz2LT, scientific=FALSE, big.mark=",")}$ values.
This reduction in memory consumption and the number of mathematical
operations will greatly accelerate the nonlinear optimization and MVN
sampling phases of the BD algorithm.


\subsection{Nonlinear optimization}\label{sec:optimization}

Finding the posterior mode $\theta^*$ can be a hard problem when there
is a high number of variables, especially when using standard
optimization routines, like the \func{optim} function in base
\proglang{R}, and others that are described in the CRAN Task View on
Optimization.  There are two common problems with these algorithms:

\paragraph{Premature termination}  Many algorithms apply a stopping rule that is based on
whether the optimizer is making "sufficient progress.'' If the
objective function does not improve by some minimum amount, the
algorithm believes that it has converged to a local optimum. This can happen before the gradient of the
objective function is sufficiently flat.  When that happens, a MVN
distribution around that apparent posterior mode is not a valid
approximation to the posterior.  For an unconstrained objective
function, the \emph{only} appropriate stopping rule is whether a
function of the gradient (e.g., the Euclidean norm) is numerically
zero.  Any optimization routine that stops before that is stopping
prematurely.

\paragraph{Poor scalability}   Search methods like Nelder-Mead (the default algorithm for
\func{optim}) are inefficient with a
massive number of parameters because the search space is large, and
they do not exploit information about slope and curvature to speed up
the time to convergence.  Conjugate gradient (\method{CG}) and
quasi-Newton (e.g., \method{BFGS}) do use
gradient information, with \method{BFGS} tracing out the curvature of
the function by using successive gradients to approximate the inverse
Hessian.  However, because \method{BFGS} stores the entire dense
inverse Hessian, its use is resource-intensive when the number of
parameters is large.   CG methods do not store the full Hessian
(or its inverse), so they can be more suited for large-scale
problems. Like \method{BFGS}, they are not certain to
approximate the curvature of the objective function accurately at any
particular iteration, especially if the function is not convex \citep{R_trustOptim}.

A better choice of nonlinear optimizer would be one that uses exact calculations of the gradient and Hessian,
remains scalable for large problems, terminates only when the norm of the
gradient is numerically zero, and is stable when passing through
regions in which the surface of the objective function is flat.  The \func{trust.optim} function
in the \pkg{trustOptim} package meets those criteria.
\Citet{R_trustOptim} describes the many advantages of the
\func{trust.optim} function.  Two advantages of note are:

\begin{enumerate}
\item convergence only when the norm of the
  gradient is sufficiently close to zero; and
\item the ability to use curvature information from a sparse Hessian.
\end{enumerate}

The \func{trust.optim} function supports three optimization routines:
two quasi-Newton methods (\method{SR1} and \method{BFGS}; see
\citet{NocedalWright2006}), and \method{Sparse}.  All three
methods require the user to supply a function that returns the value
of the objective function, \emph{and} a function that returns the
gradient.  The \method{Sparse} method requires an additional function
that returns the Hessian as a \class{dgCMatrix} object (defined in the
\pkg{Matrix} package).


\subsection{Computing derivatives}\label{sec:derivatives}

Nearly all reasonable choices of a nonlinear optimization algorithm
require the user to provide a the gradient of the objective function.
The \method{Sparse} method for \func{trust.optim} requires the Hessian
as well.  The Hessian is also required to approximate the posterior density with a MVN
distribution around the posterior mode.

For the purposes of the BD algorithm, there are two "good" ways to
compute a derivative. The first is to derive
it analytically, and write a function to compute it.  This approach is
straightforward, but it can be tedious and error-prone for complicated
models.  The second is to use automatic,
or algorithmic, differentiation (AD).  In short, AD generates
code for the derivative by applying the chain rule on the same sequence of operations
that computes the objective function.  The AD software redefines basic
functions like addition, multiplication, exponentiation, and so forth,
so derivative information is accumulated at the same time the
objective function is being evaluated.  When needed, the AD routine will return
the gradient in time that is proportional to the time needed to compute the
objective function, \emph{regardless of the number of independent variables}.


There are a number of different approaches to
implementing AD, and AD libraries are available for
many programming languages.  However, as of now, there are none for \proglang{R} that are
well-suited for a general class of Bayesian hierarchical models.  For
\proglang{R} users, we believe that coding the objective function in \proglang{C++} using the
\pkg{CppAD} library, and interfacing with \proglang{R} using \pkg{Rcpp}, is the best option
at the moment.  How to do this will be the subject of a future
vignette.  What matters is that functions that return the gradient and
Hessian of the log posterior density are available, and that they are sufficiently
accurate.  The advantage of both analytic and AD derivatives is that
they are ``exact,'' at least up to machine precision \citep{GriewankWalther2008}.

We do not recommend estimating the gradient by numerical approximation via finite
differencing (FD).  FD involves computing
$\dfrac{\partial f}{\partial x_j}\approx\dfrac{f(x_j+h)-f(x_j)}{h}$, or some variation thereof, for each of the $j=1...J$ variables,
using an arbitrarily small $h$ as a ``perturbation factor.''  As $h\rightarrow 0$, this estimated
difference approaches the gradient.  Not only are FD methods vulnerable
to numerical precision problems, but the complexity of the method
grows with the number of variables   Thus, FD is not a reasonable
option for estimating the gradient
when the number of variables is large.  The time to compute the
gradient using AD, on the
other hand, is only a small fixed multiple of the time to compute the
objective function, regardless of the number of variables.

The computational cost of computing a dense Hessian using FD is
quadratic in the number of variables, and the numerical precision
problems are even more pronounced than for a gradient.  Nevertheless,
one can use FD to estimate the Hessian if the Hessian is sparse, \emph{and} the
sparsity pattern is known in advance, \emph{and} the gradient is
exact (either derived analytically or computed using AD).  The
\pkg{sparseHessianFD} package defines an \proglang{R} class for doing
this (the algorithms are based on \citet{ColemanGarbow1985} and
\citet{ColemanGarbow1985b}). An object
of class \class{sparseHessianFD} is initialized with the objective
function and its gradient, as well as the row
and column indices of the non-zero elements of the lower triangle of
the Hessian.  The \class{sparseHessianFD} class defines a member
function that returns the sparse Hessian a \class{dgCMatrix}
object.

The \class{sparseHessianFD} class is useful for
hierarchical models because the
sparsity pattern is predictable and should not change.
Even if the Hessian were derived analytically, it still may be faster
to use \class{sparseHessianFD} for
repeated estimation, because of the way the package exploits sparsity.  Given the typical sparsity pattern of a hierarchical model, the time to estimate
a Hessian using \pkg{sparseHessianFD} does not grow with the number of
heterogeneous units, making it a scalable way of estimating sparse Hessians for large datasets.

The trade-off from using the \pkg{sparseHessianFD} package is that the
Hessian is still a numerical approximation.  We cannot guarantee that
this approximation is "good enough" for all cases.  However, the
performance of an optimization algorithm is likely to be more sensitive to
numerical imprecision in the gradient than in the Hessian. Thus, we
are comfortable working with finite-differenced sparse Hessians, even though
we will not use finite-differenced gradients.  This approach will
almost certainly fail if the gradient itself is estimated using FD.
In that case, the estimate of the Hessian would be a finite difference of finite
differences, with too much numerical imprecision to be of much
value.


\subsection{High-dimensional MVN distribution}\label{sec:MVN}


The BD algorithm requires a careful selection of a proposal density.
A MVN distribution, with a mean at $\theta^*$ and a precision matrix
equal to the negative Hessian, times a scaling constant,
is a reasonable choice for many models.  However, when the covariance
matrix is dense, the complexity of sampling from, and
computing the density of, an MVN is quadratic in the number of
variables.

The \pkg{mvtnorm} provides the functions \func{rmvnorm} to sample from
the MVN distribution, and \func{dmvnorm} to compute the density.  Both
arguments require the user to provide a dense covariance matrix as one of
the arguments. Since the negative Hessian (the precision matrix) is the \emph{inverse} of the
covariance, the \pkg{mvtnorm} functions require an explicit matrix
inversion. Even if the Hessian is sparse, its inverse may not be.
Also, each
call to \func{rmvnorm} or \func{dmvnorm} involves matrix
factorization, and linear operations on the factors, neither of which
are scalable when the matrix is dense.

The \pkg{sparseMVN} package is a solution to these problems.  Instead of
requiring a covariance matrix as one of the arguments, the \func{rmvn.sparse} and
\func{dmvn.sparse} functions take the Cholesky
decomposition of a sparse covariance or sparse precision
matrix.  Thus, the user can choose either the covariance
or precision matrix, depending on which is more convenient.  The sparse
Cholesky decomposition must be an object of the \class{Cholesky} object, which
is defined in the \pkg{Matrix} package, and returned by the
\func{Cholesky} function.  Since the size
of the sparse Hessian grows only linearly with the size of the
dataset, \func{rmvn.sparse} and \func{dmvn.sparse} are scalable
alternatives to \func{rmvnorm} and \func{dmvnorm}.

\section{Example:  hierarchical binary choice}\label{sec:example}

Before going into the details of how to put all of the pieces of the
BD algorithm together, let's
consider the following example of a log posterior density function
with a sparse Hessian.
 Suppose we have a dataset of $N$ households, each with $T$
 opportunities to purchase a particular product.  Let $y_i$ be the
 number of times household $i$ purchases the product, out of the $T$
 purchase opportunities.  Furthermore, let $p_i$ be the probability of
 purchase; $p_i$ is the same for all $T$ opportunities, so we can treat $y_i$ as a binomial random variable.  The purchase probability
 $p_i$ is heterogeneous, and depends on both $k$ continuous covariates
 $x_i$, and a heterogeneous coefficient vector $\beta_i$, such that
\begin{align}
  p_i=\frac{\exp(x_i'\beta_i)}{1+\exp(x_i'\beta_i)},~i=1 ... N
\end{align}

The coefficients can be thought of as sensitivities to the covariates,
and they are distributed across the population of households following
a multivariate normal distribution with mean $\mu$ and covariance
$\Sigma$.   We assume that we know $\Sigma$, but we do not know $\mu$.
Instead, we place a multivariate normal prior on $\mu$, with mean $0$
and covariance $\Omega_0$.  Thus, each $\beta_i$, and $\mu$ are
$k-$dimensional vectors, and the total number of unknown variables in
the model is $(N+1)k$.

In this model, we will make an assumption of \emph{conditional
  independence} across households.   A household's purchase count $y_i$
depends on that household's $\beta_i$, but not the
parameters of any other household, $\beta_j$, conditional on other
population level parameters.  Since $\mu$ and $\Sigma$ depend on
$\beta_i$ for \emph{all} households, we cannot say that $y_i$ and $y_j$ are
truly independent.  A change in $\beta_i$ affects $\mu$ and
$\Sigma$, which in turn affect $\beta_j$ for some other household
$j$.  However, if we condition on $\mu$ and $\Sigma$, then $y_i$ and $y_j$
are independent, so we describe the data likelihoods as conditionally independent.

This conditional independence assumption is what allows us to write
the joint likelihood of the data as a product of individual-level
probability models.  Therefore, the log posterior density, ignoring any normalization constants, is
\begin{align}
  \log \pi(\beta_{1:N},\mu|Y, X, \Sigma_0,\Omega_0)=\sum_{i=1}^Np_i^{y_i}(1-p_i)^{T-y_i}
  -\frac{1}{2}\left(\beta_i-\mu\right)'\Sigma^{-1}\left(\beta_i-\mu\right)
-\frac{1}{2}\mu'\Omega_0^{-1}\mu
\end{align}

\subsection{Functions, sample data, and priors for the example}

The \pkg{bayesGDS} package includes a simulated dataset for $N$ households and $k$
covariates per household.  A household makes $Y$ purchases out of $T$
opportunities.  The purchase probability for each household depends on
a covariate matrix $X$.  So let's start by loading the data, and setting hyperprior values for $\Sigma^{-1}$ and $\Omega^{-1}$.

<<data>>=
@


The function \func{binary.f} returns the unnormalized log
posterior density of this model, $\log\Dy$, evaluated at the vector passed as the
first argument.  This function takes two additional named arguments,
\funcarg{data} and \funcarg{priors}.  The
function \funcarg{binary.grad} returns the gradient, and
\funcarg{binary.hess} returns the sparse Hessian (as a \class{dgCMatrix} object).


<<startingVals>>=
@

\subsection{Using sparseHessianFD when the Hessian is unknown}

Hessians can be difficult to derive analytically, but for hierarchical
models, they have predictable sparsity patterns. The
\pkg{sparseHessianFD} package simplifies numerical approximation of a
sparse Hessian, and can be used if exact
methods are unavailable (see Section \ref{sec:derivatives}.   The
\func{sparseHessianFD.new} function is a wrapper around the
constructor for the \class{sparseHessianFD} class, and returns an
object of that class.  But before calling \func{sparseHessianFD.new},
we need to get the sparsity pattern of the lower triangle of the
Hessian. The sparsity pattern is defined
by integer vectors of the row and column indices of the non-zero elements.

A straightforward
way to generate the sparsity pattern is to build a sparse integer,
logical, or pattern matrix (using the \pkg{Matrix} package) that has
the same sparsity pattern as the Hessian. The \func{Matrix.to.Coord}
function from the
\pkg{sparseHessianFD} will extract the row and columns of the
non-zeros, and return them in a list of two integer vectors.

<<hessStruct>>=
@

Now we can construct the \class{sparseHessianFD} object.

<<sparseHessianFD>>=
@

One advantage to using \pkg{sparseHessianFD} is that
additional arguments that need to be passed to the objective function
(e.g., data or prior parameters) are stored within the object. The
member functions \func{fn}, \func{gr} and \func{hessian} take only
one argument.

<<usingFD>>=
@

The upper-left
  corner of the Hessian is sparse (the entire Hessian is too big to
  print), and \code{FD\$hessian} returns the
  same matrix as \code{binary.hess}.

<<hessUpperLeft, collapse=TRUE>>=
@

\section{Running the algorithm}\label{sec:runAlgorithm}

Now it's time to estimate the posterior distributions of the model parameters.

\subsection{Finding the posterior mode}

The \func{trust.optim} function in the \pkg{trustOptim} package exploits the sparsity of
the Hessian of the objective function, and it uses the gradient of the
objective function to determine when it has converged to a local
optimum.  For the \funcarg{fn}, \funcarg{gr} and \funcarg{hs}
arguments, we provide the corresponding member functions from
\variable{FD}, which we constructed using \func{sparseHessianFD.new}.  Details
on the control list are available in the \pkg{trustOptim} documentation.
The most important control option to mention here is that
\funcarg{function.scale.factor} must be positive for minimization, and
negative for maximization.

<<trustOptim>>=
@


\subsection{Defining proposal functions}

Next, we define a function to sample from a proposal density, and a
function to compute $\log\Dy$ for each proposal draw.  These
functions take a variable vector as the first argument, and list of
proposal parameters as the second argument.  As discussed in Section \ref{sec:MVN}, the
functions in the \pkg{sparseMVN} package require two parameters:  a mean
vector, and a Cholesky decomposition of either the covariance or
precision matrix.  That means we need some wrapper functions.


<<defPropFuncs>>=
@

The proposal mean is
the posterior mean, $\theta^*$.  The proposal precision is the negative Hessian,
times a scaling factor.  Use \func{Cholesky} (defined in
\pkg{Matrix}),  and not the base \proglang{R} function
\func{chol}, which is incompatible with \pkg{sparseMVN}.


<<propParams>>=
@



\subsection{Side note:  running the algorithm in parallel}

An advantage of BD over MCMC is that both proposal and posterior
samples can be generated in parallel.  There are a number of different
mechanisms available in \proglang{R} for running jobs in parallel.  One that we
think is easy to use is based on the \pkg{parallel} package.  In the
next code chunk, I allocate 10 cores for parallel processing, and set
a random seed for simulating random variables (more on that later).
If you do not want to run the code in parallel, change the flag to
\code{run.par <- FALSE}.  This will change the number of allocated
cores to 1.

<<parallelSetup>>=
@




\subsection{Estimating the density of threshold values}
The next step in the BD algorithm is to simulate an empirical
approximation to the cumulative distribution of $\Phi(\theta|y)$.  We sample $M$
times from the proposal distribution, and compute
$\log\Phi(\theta|y)$ for each proposal sample.  Following the notation
in \citet{BraunDamien2015}, \variable{log.c1} is the log posterior density, and
\variable{log.c2} is the log of the proposal density, both evaluated at the
posterior mode $\theta^*$.

The next code chunk uses the \func{aaply} function from the \pkg{plyr} package to compute
the log posterior density for each proposal draw.  This step will run in parallel if
\code{run.par == TRUE}.

<<proposals>>=
@

The last two lines in the previous code chunk are checks that
$\log\Phi(\theta|y)\leq 0$ for all of the proposal draws.  If the check fails, then
the proposal distribution is invalid.  Make the proposal distribution
more diffuse by reducing the scaling factor on the negative
Hessian. Then, try again.

Helpful hint:  If $M$ is too small, there may not be enough proposal draws to confirm
that the proposal distribution is sufficiently diffuse, even if
$\log\Phi(\theta|y)\leq 0$ for all of those $M$ proposals. This can
cause problems later.  So don't try to make the proposal distribution
too ``tight.''  Time invested in ``optimizing'' the
proposal distribution is not a well-used resource.


\subsection{Posterior draws via rejection sampling}

 \emph{Finally} we can start sampling from the posterior density,
 using functions in the \pkg{bayesGDS} package.  We should proceed to
 this step only if \code{valid.scale==TRUE}.

 The \func{sample.GDS} function is the ``workhorse'' function of
 \pkg{bayesGDS}.  Each call to \func{sample.GDS} collects posterior
 samples serially.  The argument \funcarg{n.draws} is the number of draws for that
 particular call to \func{sample.GDS}. The other required arguments to
 \func{sample.GDS} are the $M$-length vector of $\log\Phi(\theta|y)$,
 the posterior mode $\theta^*$; the function that returns the log
 posterior density; the functions that sample from, and compute the
 log density of, the proposal distribution; parameters of the proposal
 distribution.  See the \pkg{bayesGDS} package documentation for
 descriptions of the function arguments.

 The following code chunk is a single-core implementation.

<<sampleGDS_serial>>=
@


We can use the \pkg{foreach}
package to run \func{sample.GDS} in parallel on multiple processing
units.  Each instance of \func{sample.GDS} is responsible for a batch of
posterior draws.  If we need \variable{n.draws} samples from the
posterior, and we want to run \variable{n.batch} instances of
\func{sample.GDS}, then each instance will collect
\variable{batch.size} samples.  The return object of \func{foreach} is
a list, with each element being a return object of \func{sample.GDS}.
The order in which the \func{sample.GDS} objects are returned does not matter.
Samples can be identified by batch with the \funcarg{thread.id}
argument.  It is important to start each instance with a different
random seed, which we specify in the \funcarg{seed} argument.

When all processing cores have finished collecting their samples, we
combine the list elements using a Map-Reduce construct.

<<sampleGDS_parallel, echo = TRUE, results = 'asis'>>=
@




\subsection{The output}

Let's take a look at the \func{sampleGDS} output.

<<strDraws>>=
@

The \funcarg{draws} element has a posterior sample in each row.  Each
column is a variable.  The \funcarg{counts}
vector contains the number of proposal draws that were necessary to
accept that particular posterior draw.  This vector is needed to
compute the log marginal likelihood (LML, see below), and to assess
the efficiency of the algorithm.  The \funcarg{gt.1} vector flags whether a
threshold value was greater than 1.  This is an important check,
because if any elements of that vector are 1, that means that the
proposal density was still just a bit too tight.  If this is the case
for only a couple of draws, it's probably not a big deal.  If it is
true for a large number of draws, not only is the proposal density
invalid, but something probably went wrong earlier in the algorithm.
Maybe $M$ was too small.

You can get summaries and quantiles for your parameters of interest in
the standard way.  In this case, let's just summarize the
population-level parameters.

<<summary, collapse=TRUE>>=
@


If any elements in \funcarg{counts} is NA, it means that the proposal count reached the
value in \funcarg{max.tries} without an acceptance.  This would suggest an inefficient sampler that
requires further investigation.

\section{Estimating the log marginal likelihood}


The log marginal likelihood (LML) is the likelihood of the data under
the model, $\Ly$.  For better or worse, the LML is often used for model comparison (e.g.,
computing Bayes factors).  As discussed in \citet{BraunDamien2015},
there is no generally accepted method for computing the LML from MCMC
output.  However, estimating the LML using the \func{LML} function in
this package is straightforward.  All of the arguments to \func{LML}
were used in earlier function calls, or returned by
\func{sample.GDS}.


<<LML>>=
@


\section{Future development}

The \pkg{bayesGDS} package remains incomplete.  Here are some
improvements and enhancements that are under consideration for future releases.

\begin{enumerate}
\item A wrapper function for the entire BD algorithm;
\item Functions to summarize and display the output;
\item Options to retain a subset of variables and discard others
  (e.g., keep only population-level parameters);
\item A simpler interface for parallel sampling;
\item More examples of different kinds of applications;
\end{enumerate}



\printbibliography

\end{document}

%%  LocalWords:  dmvnorm
